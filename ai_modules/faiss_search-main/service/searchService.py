import faiss
import numpy as np
import ast
import logging
from typing import Dict, List, Optional
from openai import OpenAI
from service.queryService import QueryService

logger = logging.getLogger(__name__)


class SearchService:
    """ê°„ë‹¨í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: SQL â†’ FAISS"""

    def __init__(self, openai_client: OpenAI, db_client):
        self.llm_client = openai_client
        self.db_client = db_client
        self.query_service = QueryService(openai_client, db_client)

    def generate_embedding(self, text: str) -> Optional[np.ndarray]:
        """í…ìŠ¤íŠ¸ë¥¼ OpenAI ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        try:
            response = self.llm_client.embeddings.create(
                model="text-embedding-ada-002",
                input=text,
                encoding_format="float"
            )
            embedding = np.array(response.data[0].embedding, dtype=np.float32)
            return embedding
        except Exception as e:
            logger.error(f"âŒ [SearchService] ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def search_hybrid(self, query_text: str, count: int = 10) -> List[Dict]:
        """ê°„ë‹¨í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: SQL â†’ FAISS (SQL ì‹¤íŒ¨ì‹œ ì „ì²´ DB ê²€ìƒ‰)"""
        logger.info(f"ğŸš€ [SearchService] ê²€ìƒ‰ ì‹œì‘: '{query_text}'")

        # 1. SQLë¡œ ê´€ë ¨ ê°•ì˜ í•„í„°ë§
        filtered_courses = self.query_service.get_filtered_courses(query_text)

        if not filtered_courses:
            logger.warning("âš ï¸ [SearchService] SQL í•„í„°ë§ ê²°ê³¼ ì—†ìŒ - ì „ì²´ DBì—ì„œ ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰")
            # SQL í•„í„°ë§ì´ ì‹¤íŒ¨í•˜ë©´ ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë²¡í„° ê²€ìƒ‰
            filtered_courses = self._get_all_courses_with_vectors()
            if not filtered_courses:
                logger.error("âŒ [SearchService] ì „ì²´ DB ì¡°íšŒ ì‹¤íŒ¨")
                return []
            logger.info(f"ğŸ“Š [SearchService] ì „ì²´ DB ê²€ìƒ‰: {len(filtered_courses)}ê°œ ê°•ì˜")
        else:
            logger.info(f"ğŸ“Š [SearchService] SQL í•„í„°ë§ ê²°ê³¼: {len(filtered_courses)}ê°œ ê°•ì˜")

        # 2. í•„í„°ë§ëœ ê°•ì˜ë¡œ ë²¡í„° ê²€ìƒ‰
        results = self._search_in_filtered_courses(query_text, filtered_courses, count)

        logger.info(f"âœ… [SearchService] ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
        return results

    def _search_in_filtered_courses(self, query_text: str, filtered_courses: List[Dict], count: int) -> List[Dict]:
        """í•„í„°ë§ëœ ê°•ì˜ë“¤ë¡œë§Œ ë²¡í„° ê²€ìƒ‰"""
        logger.info(f"ğŸ¯ [SearchService] ë²¡í„° ê²€ìƒ‰ ì‹œì‘: {len(filtered_courses)}ê°œ ê°•ì˜")

        # 1. ë²¡í„° ë°ì´í„° ì¤€ë¹„
        vectors = []
        metadata = []

        for course in filtered_courses:
            try:
                vector_str = course.get('vector', '[]')
                if not vector_str or vector_str == '[]':
                    continue

                vector = ast.literal_eval(vector_str)
                vector_array = np.array(vector, dtype=np.float32)

                # ì •ê·œí™”
                norm = np.linalg.norm(vector_array)
                if norm > 0:
                    vector_array = vector_array / norm

                vectors.append(vector_array)
                metadata.append({
                    'id': course['id'],
                    'name': course['name'],
                    'department': course.get('department_full_name', course.get('department', '')),
                    'professor': course.get('professor', 'ì •ë³´ì—†ìŒ'),
                    'credits': course.get('credits', 0),
                    'schedule': course.get('schedule', 'ì •ë³´ì—†ìŒ'),
                    'location': course.get('location', 'ì •ë³´ì—†ìŒ'),
                    'delivery_mode': course.get('delivery_mode', 'ì •ë³´ì—†ìŒ'),
                    'gpt_description': course.get('gpt_description', ''),
                    'description': course.get('gpt_description', ''),
                })

            except Exception as e:
                logger.warning(f"âš ï¸ [SearchService] ë²¡í„° íŒŒì‹± ì‹¤íŒ¨: {course.get('name', 'Unknown')} - {e}")
                continue

        if not vectors:
            logger.error("âŒ [SearchService] ìœ íš¨í•œ ë²¡í„° ë°ì´í„° ì—†ìŒ")
            return []

        logger.info(f"âœ… [SearchService] ìœ íš¨í•œ ë²¡í„°: {len(vectors)}ê°œ")

        # 2. FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ê²€ìƒ‰
        try:
            vectors = np.array(vectors)
            logger.info(f"ğŸ”§ [SearchService] ë²¡í„° ë°°ì—´ ìƒì„±: shape={vectors.shape}")

            index = faiss.IndexFlatIP(vectors.shape[1])
            index.add(vectors)
            logger.info(f"ğŸ”§ [SearchService] FAISS ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: dimension={vectors.shape[1]}")

            # ì¿¼ë¦¬ ë²¡í„° ìƒì„±
            logger.info(f"ğŸ”§ [SearchService] ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹œì‘: '{query_text}'")
            query_vector = self.generate_embedding(query_text)
            if query_vector is None:
                logger.error("âŒ [SearchService] ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                return []

            logger.info(f"ğŸ”§ [SearchService] ì¿¼ë¦¬ ë²¡í„° ìƒì„± ì™„ë£Œ: shape={query_vector.shape}")
            query_vector = query_vector.reshape(1, -1).astype(np.float32)
            query_vector = query_vector / np.linalg.norm(query_vector)
            logger.info(f"ğŸ”§ [SearchService] ì¿¼ë¦¬ ë²¡í„° ì •ê·œí™” ì™„ë£Œ: shape={query_vector.shape}")

            # ê²€ìƒ‰
            search_count = min(count, len(vectors))
            logger.info(f"ğŸ”§ [SearchService] FAISS ê²€ìƒ‰ ì‹œì‘: search_count={search_count}")
            scores, indices = index.search(query_vector, search_count)
            logger.info(f"ğŸ”§ [SearchService] FAISS ê²€ìƒ‰ ì™„ë£Œ: scores={scores[0][:3]}, indices={indices[0][:3]}")

            # ê²°ê³¼ êµ¬ì„±
            results = []
            for i, idx in enumerate(indices[0]):
                if idx < len(metadata) and scores[0][i] > 0:
                    result = metadata[idx].copy()
                    result['similarity_score'] = float(scores[0][i])
                    result['similarity'] = float(scores[0][i])
                    results.append(result)
                    logger.info(f"ğŸ”§ [SearchService] ê²°ê³¼ {i+1}: {result['name']}, score={scores[0][i]:.4f}")

            logger.info(f"ğŸ¯ [SearchService] ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results[:count]

        except Exception as e:
            logger.error(f"âŒ [SearchService] ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            import traceback
            logger.error(f"âŒ [SearchService] ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return []

    def _get_all_courses_with_vectors(self) -> List[Dict]:
        """ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë²¡í„° ë°ì´í„°ë¥¼ í¬í•¨í•œ ê°•ì˜ ëª©ë¡ ë°˜í™˜"""
        try:
            if not self.db_client.ensure_connection():
                return []

            with self.db_client.connection.cursor() as cursor:
                sql = """
                SELECT id, name, department_full_name, department, professor, credits,
                       schedule, location, delivery_mode, gpt_description, vector
                FROM jbnu_class_gpt
                WHERE vector IS NOT NULL AND vector != '[]'
                LIMIT 1000
                """

                logger.info("ğŸ” [SearchService] ì „ì²´ DBì—ì„œ ë²¡í„° ë°ì´í„° ì¡°íšŒ")
                cursor.execute(sql)
                results = cursor.fetchall()

                logger.info(f"ğŸ“Š [SearchService] ì „ì²´ DB ì¡°íšŒ ê²°ê³¼: {len(results)}ê°œ ê°•ì˜")
                return results

        except Exception as e:
            logger.error(f"âŒ [SearchService] ì „ì²´ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []