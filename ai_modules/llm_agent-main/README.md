# JBNU AI Mentor - LLM Agent Service

**JBNU AI ë©˜í†  ì‹œìŠ¤í…œì˜ í•µì‹¬ LLM ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤**

## ğŸ“– ê°œìš”

LLM AgentëŠ” JBNU AI Mentor ì‹œìŠ¤í…œì˜ ì¤‘ì‹¬ ì„œë¹„ìŠ¤ë¡œ, LangGraph ê¸°ë°˜ì˜ ë³µì¡ë„ë³„ ì¿¼ë¦¬ ì²˜ë¦¬ì™€ ë‹¤ì¤‘ ë°ì´í„° ì†ŒìŠ¤ í†µí•©ì„ í†µí•´ ì§€ëŠ¥í˜• êµìœ¡ ìƒë‹´ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### í•µì‹¬ êµ¬ì„±ìš”ì†Œ
```
llm_agent-main/
â”œâ”€â”€ main.py                       # FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
â”œâ”€â”€ controller/
â”‚   â””â”€â”€ agentController.py        # API ì»¨íŠ¸ë¡¤ëŸ¬
â”œâ”€â”€ service/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ unified_langgraph_app.py   # í†µí•© LangGraph ì• í”Œë¦¬ì¼€ì´ì…˜
â”‚   â”‚   â”œâ”€â”€ langgraph_state.py         # LangGraph ìƒíƒœ ê´€ë¦¬
â”‚   â”‚   â””â”€â”€ memory.py                  # ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ query_analyzer.py          # ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„
â”‚   â”‚   â”œâ”€â”€ context_analyzer.py        # ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
â”‚   â”‚   â””â”€â”€ result_synthesizer.py      # ê²°ê³¼ í•©ì„±
â”‚   â””â”€â”€ nodes/
â”‚       â””â”€â”€ node_manager.py            # LangGraph ë…¸ë“œ ê´€ë¦¬
â”œâ”€â”€ processors/
â”‚   â”œâ”€â”€ router.py                 # ë¼ìš°íŒ… ë¡œì§
â”‚   â””â”€â”€ chain_processor.py        # ì²´ì¸ ì²˜ë¦¬ê¸°
â”œâ”€â”€ handlers/
â”‚   â”œâ”€â”€ vector_search_handler.py  # FAISS ë²¡í„° ê²€ìƒ‰
â”‚   â”œâ”€â”€ sql_query_handler.py      # SQL ë°ì´í„°ë² ì´ìŠ¤
â”‚   â”œâ”€â”€ department_mapping_handler.py  # í•™ê³¼ ë§¤í•‘
â”‚   â””â”€â”€ curriculum_handler.py     # ì»¤ë¦¬í˜ëŸ¼ ê³„íš
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ llm_client_langchain.py   # LangChain LLM í´ë¼ì´ì–¸íŠ¸
â”‚   â”œâ”€â”€ prompt_loader.py          # í”„ë¡¬í”„íŠ¸ ê´€ë¦¬
â”‚   â””â”€â”€ json_utils.py             # JSON ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ prompts/                      # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py               # ì„¤ì • ê´€ë¦¬
â””â”€â”€ logs/                         # ë¡œê·¸ íŒŒì¼
```

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

### 1. LangGraph ê¸°ë°˜ ë³µì¡ë„ë³„ ì²˜ë¦¬

#### Light ë³µì¡ë„
- **ì¼ë°˜ ì§ˆë¬¸**: ì§ì ‘ LLM ì‘ë‹µ
- **ì¸ì‚¬ë§**: ê°„ë‹¨í•œ í™˜ì˜ ë©”ì‹œì§€

#### Medium ë³µì¡ë„
- **SQL ì¿¼ë¦¬**: ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
- **ë²¡í„° ê²€ìƒ‰**: FAISS ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰
- **ì»¤ë¦¬í˜ëŸ¼**: í•™ìŠµ ê³„íš ìˆ˜ë¦½
- **ì—ì´ì „íŠ¸**: íŠ¹ìˆ˜ ë„ë©”ì¸ ì²˜ë¦¬

#### Heavy ë³µì¡ë„
- **ìˆœì°¨ ì²˜ë¦¬**: ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ ìˆœì°¨ í™œìš©
- **ë³µí•© ì¿¼ë¦¬**: ë‹¤ë‹¨ê³„ ì¶”ë¡  í•„ìš”

### 2. ì¿¼ë¦¬ ë¶„ì„ ì‹œìŠ¤í…œ

#### ë³‘ë ¬ ë¶„ì„ (analyze_query_parallel)
```python
# 1ë‹¨ê³„: ì¿¼ë¦¬ í™•ì¥
expansion_result = await self._expand_query_async(query, history_context)

# 2ë‹¨ê³„: í–¥ìƒëœ ì¿¼ë¦¬ ìƒì„±
enhanced_query = self._combine_expansion_with_query(query, expansion_result)

# 3ë‹¨ê³„: ë¼ìš°íŒ… ë¶„ì„
analysis_result = await self._analyze_routing_async(enhanced_query, contextual_prompt, history_context)
```

#### í™•ì¥ ì •ë³´
- **expansion_context**: ë°°ê²½ ì •ë³´
- **expansion_keywords**: ê´€ë ¨ í‚¤ì›Œë“œ
- **expanded_queries**: ë²¡í„° ê²€ìƒ‰ìš© í™•ì¥ ì¿¼ë¦¬

### 3. ë‹¤ì¤‘ ë°ì´í„° ì†ŒìŠ¤ í†µí•©

#### ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ë™
```python
# ì„¤ì • íŒŒì¼ (config/settings.py)
sql_query_url = "http://svc7999:7999/api/v1/agent"           # SQL ë°ì´í„°ë² ì´ìŠ¤
faiss_search_url = "http://svc7997:7997/search"             # ë²¡í„° ê²€ìƒ‰
curriculum_plan_url = "http://localhost:7996/chat"          # ì»¤ë¦¬í˜ëŸ¼ ê³„íš
department_mapping_url = "http://department-mapping:8000/agent"  # í•™ê³¼ ë§¤í•‘
llm_fallback_url = "http://svc7998:7998/agent"              # í´ë°± LLM
```

## ğŸ“¡ API ì—”ë“œí¬ì¸íŠ¸

### ë©”ì¸ ì—ì´ì „íŠ¸ API
```http
POST /api/v2/agent
Content-Type: application/json

{
  "message": "ì»´í“¨í„°ê³µí•™ê³¼ ì¡¸ì—…ìš”ê±´ì„ ì•Œë ¤ì£¼ì„¸ìš”",
  "session_id": "user123",
  "stream": false
}
```

### ìŠ¤íŠ¸ë¦¬ë° API
```http
POST /api/v2/agent-stream
Content-Type: application/json

{
  "message": "ë¨¸ì‹ ëŸ¬ë‹ ê³µë¶€ ê³„íšì„ ì„¸ì›Œì£¼ì„¸ìš”",
  "session_id": "user123"
}
```

### OpenAI í˜¸í™˜ API
```http
POST /api/chat/completions
Content-Type: application/json

{
  "model": "ai-mentor",
  "messages": [
    {"role": "user", "content": "í”„ë¡œê·¸ë˜ë° ì–¸ì–´ ì¶”ì²œí•´ì£¼ì„¸ìš”"}
  ],
  "stream": true
}
```

## ğŸ”§ í•µì‹¬ êµ¬ì„±ìš”ì†Œ ìƒì„¸

### UnifiedLangGraphApp (service/core/unified_langgraph_app.py)

**í†µí•© LangGraph ì• í”Œë¦¬ì¼€ì´ì…˜ - ëª¨ë“  ë³µì¡ë„ ì²˜ë¦¬**

```python
class UnifiedLangGraphApp:
    def __init__(self, conversation_memory: ConversationMemory = None):
        # ê¸°ì¡´ ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™”
        self.query_analyzer = QueryAnalyzer()
        self.vector_handler = VectorSearchHandler()
        self.sql_handler = SqlQueryHandler()
        # ... ê¸°íƒ€ í•¸ë“¤ëŸ¬ë“¤

        # ê·¸ë˜í”„ ë¹Œë“œ
        self.graph = self._build_unified_graph()
```

**ê·¸ë˜í”„ íë¦„:**
```
START â†’ router â†’ [ë³µì¡ë„ë³„ ë…¸ë“œ] â†’ synthesis â†’ finalize â†’ END
```

### QueryAnalyzer (service/analysis/query_analyzer.py)

**LangChain ê¸°ë°˜ ì¿¼ë¦¬ ë¶„ì„ê¸°**

**ì£¼ìš” ë©”ì„œë“œ:**
- `analyze_query_parallel()`: ë³‘ë ¬ ì¿¼ë¦¬ ë¶„ì„ + í™•ì¥
- `_expand_query_async()`: ë¹„ë™ê¸° ì¿¼ë¦¬ í™•ì¥
- `_analyze_routing_async()`: ë¹„ë™ê¸° ë¼ìš°íŒ… ë¶„ì„
- `_get_history_context()`: íˆìŠ¤í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ

**ë¶„ì„ ê²°ê³¼:**
```python
{
    "decision_question_type": "curriculum",
    "decision_data_source": "vector",
    "complexity": "medium",
    "owner_hint": "curriculum-handler",
    "plan": ["ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘", "ì»¤ë¦¬í˜ëŸ¼ ê³„íš ìˆ˜ë¦½"],
    "expansion_context": "ì»´í“¨í„°ê³µí•™ê³¼ ê´€ë ¨ ë°°ê²½ì •ë³´",
    "expansion_keywords": "ì¡¸ì—…ìš”ê±´, í•™ì , í•„ìˆ˜ê³¼ëª©"
}
```

### NodeManager (service/nodes/node_manager.py)

**LangGraph ë…¸ë“œ ê´€ë¦¬ì**

**ì œê³µ ë…¸ë“œë“¤:**
- `router`: ë³µì¡ë„ ë¶„ì„ ë° ë¼ìš°íŒ…
- `light_llm`: ê°„ë‹¨í•œ LLM ì‘ë‹µ
- `light_greeting`: ì¸ì‚¬ë§ ì²˜ë¦¬
- `medium_sql`: SQL ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
- `medium_vector`: FAISS ë²¡í„° ê²€ìƒ‰
- `medium_curriculum`: ì»¤ë¦¬í˜ëŸ¼ ê³„íš
- `medium_agent`: íŠ¹ìˆ˜ ë„ë©”ì¸ ì²˜ë¦¬
- `heavy_sequential`: ìˆœì°¨ì  ë‹¤ì¤‘ ì²˜ë¦¬
- `synthesis`: ê²°ê³¼ í•©ì„±
- `finalize`: ìµœì¢… ì²˜ë¦¬

### í•¸ë“¤ëŸ¬ ì‹œìŠ¤í…œ

#### VectorSearchHandler (handlers/vector_search_handler.py)
```python
async def search_with_analysis(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
    # í™•ì¥ëœ ì¿¼ë¦¬ë“¤ì„ ì‚¬ìš©í•œ ë²¡í„° ê²€ìƒ‰
    expanded_queries = analysis_result.get("expanded_queries", [])
    # FAISS ì„œë¹„ìŠ¤ í˜¸ì¶œ
    response = await self._call_faiss_service(search_params)
```

#### SqlQueryHandler (handlers/sql_query_handler.py)
```python
async def query_with_analysis(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
    # SQL ì¿¼ë¦¬ ìƒì„± ë° ì‹¤í–‰
    query_context = self._build_query_context(analysis_result)
    # SQL ì„œë¹„ìŠ¤ í˜¸ì¶œ
    response = await self._call_sql_service(query_context)
```

## âš™ï¸ ì„¤ì • ê´€ë¦¬

### settings.py ì£¼ìš” ì„¤ì •

```python
class Settings(BaseSettings):
    # ê¸°ë³¸ ì„¤ì •
    service_name: str = "llm-agent"
    debug: bool = False
    port: int = 8001

    # LLM ì„¤ì •
    openai_api_key: Optional[str] = None
    default_model: str = "gpt-4o-mini"

    # ë©”ëª¨ë¦¬ ì„¤ì •
    max_history_length: int = 20
    max_conversation_turns: int = 10

    # ë³µì¡ë„ ë¶„ì„ ì„ê³„ê°’
    complexity_threshold: float = 0.4

    # ë³´ì•ˆ ì„¤ì •
    max_message_length: int = 10000
    max_messages_per_request: int = 100

    # ì„±ëŠ¥ ì„¤ì •
    max_concurrent_requests: int = 100
    request_timeout: int = 30

    # ì™¸ë¶€ ì„œë¹„ìŠ¤ URL
    sql_query_url: str = "http://svc7999:7999/api/v1/agent"
    faiss_search_url: str = "http://svc7997:7997/search"
    curriculum_plan_url: str = "http://localhost:7996/chat"
    department_mapping_url: str = "http://department-mapping:8000/agent"
    llm_fallback_url: str = "http://svc7998:7998/agent"
```

## ğŸ” í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ

### ì£¼ìš” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

#### router_prompt.txt
```
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì²˜ë¦¬ ë°©ë²•ì„ ê²°ì •í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {query}

ë‹¤ìŒ ì¤‘ ê°€ì¥ ì í•©í•œ ì²˜ë¦¬ ë°©ë²•ì„ JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
- question_type: [curriculum, course, department, general, greeting]
- data_source: [sql, vector, llm, department]
- complexity: [light, medium, heavy]
- owner_hint: [ë‹´ë‹¹ ì„œë¹„ìŠ¤ëª…]
- plan: [ì²˜ë¦¬ ê³„íš ë°°ì—´]
```

#### query_reasoning_prompt.txt
```
ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ í™•ì¥ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {query}

JSON í˜•íƒœë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{
  "expansion_context": "ì§ˆë¬¸ì˜ ë°°ê²½ ì •ë³´",
  "expansion_keywords": "ê´€ë ¨ í‚¤ì›Œë“œë“¤ (ì‰¼í‘œ êµ¬ë¶„)",
  "expansion_augmentation": "ì§ˆë¬¸ ë³´ì™„ ì„¤ëª…"
}
```

## ğŸ’¾ ë©”ëª¨ë¦¬ ê´€ë¦¬

### ConversationMemory (service/core/memory.py)

**ê¸°ëŠ¥:**
- ì„¸ì…˜ë³„ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
- ìµœê·¼ êµí™˜ ë‚´ì—­ ì¶”ì¶œ
- ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±

```python
class ConversationMemory:
    def add_exchange(self, session_id: str, user_message: str, ai_response: str):
        # ëŒ€í™” êµí™˜ ì €ì¥

    def get_recent_exchanges(self, session_id: str, limit: int = 5):
        # ìµœê·¼ ëŒ€í™” ë°˜í™˜

    def get_context_summary(self, session_id: str):
        # ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±
```

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### ê°œë°œ í™˜ê²½
```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export OPENAI_API_KEY="your-api-key"

# ì„œë¹„ìŠ¤ ì‹¤í–‰
python main.py
```

### Docker í™˜ê²½
```bash
# ì»¨í…Œì´ë„ˆ ë¹Œë“œ
docker build -t llm-agent .

# ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -p 8001:8001 \
  -e OPENAI_API_KEY="your-api-key" \
  llm-agent
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### ë¡œê·¸ ì„¤ì •
```python
LOGGING_CONFIG = {
    "handlers": {
        "console": {
            "level": "INFO",
            "formatter": "default",
        },
        "file": {
            "level": "DEBUG",
            "filename": "/path/to/logs/llm-agent.log",
        },
    }
}
```

### ì„±ëŠ¥ í†µê³„
```python
# QueryAnalyzerì—ì„œ ì œê³µ
stats = query_analyzer.get_performance_stats()
{
    "analyzer_type": "LangChain_v3",
    "total_analyses": 1250,
    "avg_analysis_time": 0.45,
    "success_rate": 99.2
}
```
