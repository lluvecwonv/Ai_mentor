import logging
from typing import Dict, Any
from utils.prompt_loader import load_prompt
from utils.json_utils import extract_json_block, robust_json_parse

logger = logging.getLogger(__name__)

class ConversationContextAnalyzer:
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¶„ì„ ë° í™œìš© ë°©ì‹ ê²°ì • ë¶„ì„ê¸°"""

    def __init__(self, llm_handler):
        self.llm_handler = llm_handler

    async def analyze_session_context(self, current_query: str, conversation_memory, session_id: str) -> Dict[str, Any]:
        """íˆìŠ¤í† ë¦¬ ì‚¬ìš© ì—¬ë¶€ì™€ ìƒì„¸ í™œìš© ë°©ì‹ ë¶„ì„"""
        try:
            session_state = conversation_memory.get_state(session_id)
            history = session_state.get("conversation_history", [])

            if not history:
                return {
                    "is_continuation": False,
                    "reconstructed_query": current_query,
                    "history_usage": {
                        "reuse_previous": False,
                        "relationship": "new_search",
                        "context_integration": "íˆìŠ¤í† ë¦¬ê°€ ì—†ì–´ ìƒˆë¡œìš´ ê²€ìƒ‰ ìˆ˜í–‰"
                    }
                }

            # íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…
            history_context = self._format_history(history)

            # í”„ë¡¬í”„íŠ¸ ë¡œë“œ ë° êµ¬ì„±
            prompt = load_prompt('history_aware_query_analyzer').format(
                history_context=history_context,
                current_query=current_query
            )

            # LLM í˜¸ì¶œ
            response = await self.llm_handler.chat(prompt)

            # JSON íŒŒì‹± (ë” ê°•í™”ëœ íŒŒì‹± ì‚¬ìš©)
            history_data = robust_json_parse(response)


            if history_data and isinstance(history_data, dict):
                if "history_usage" in history_data:
                    # ì •ìƒì ì¸ JSON íŒŒì‹± ì„±ê³µ
                    history_usage = history_data["history_usage"]
                    is_continuation = history_usage.get("reuse_previous", False)

                    result = {
                        "is_continuation": is_continuation,
                        "history_usage": history_usage
                    }

                            # ì—°ì†ëŒ€í™”ì¼ ê²½ìš° ì§ˆì˜ ì¬êµ¬ì„± ìˆ˜í–‰
                    if is_continuation:
                        reconstructed_query = await self._reconstruct_query(current_query, history_context)
                        result["reconstructed_query"] = reconstructed_query
                    else:
                        result["reconstructed_query"] = current_query

                    logger.info(f"ğŸ¯ íˆìŠ¤í† ë¦¬ ë¶„ì„ ì™„ë£Œ: ì—°ì†ëŒ€í™”={is_continuation}, ê´€ê³„={history_usage.get('relationship', 'unknown')}")
                    return result
                
        except Exception as e:
            logger.error(f"âŒ íˆìŠ¤í† ë¦¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
            # ì˜ˆì™¸ ë°œìƒ ì‹œ í´ë°± - ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "is_continuation": False,
                "reconstructed_query": current_query,
                "history_usage": {
                    "reuse_previous": False,
                    "relationship": "new_search",
                    "context_integration": f"ë¶„ì„ ì˜¤ë¥˜ë¡œ ìƒˆë¡œìš´ ê²€ìƒ‰: {str(e)}"
                }
            }

    def _format_history(self, history):
        """íˆìŠ¤í† ë¦¬ ê°„ë‹¨ í¬ë§·íŒ…"""
        formatted = []
        for entry in history[-3:]:  # ìµœê·¼ 3í„´ë§Œ
            if entry.get("role") == "user":
                formatted.append(f"ì‚¬ìš©ì: {entry.get('content', '')}")
            elif entry.get("role") == "assistant":
                formatted.append(f"AI: {entry.get('content', '')[:100]}...")
        return " | ".join(formatted)
    

    async def _reconstruct_query(self, current_query: str, history_context: str) -> str:
        # ì§ˆì˜ ì¬êµ¬ì„± í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        reconstruction_prompt = load_prompt('query_reconstruction').format(
            history_context=history_context,
            current_query=current_query
        )

        reconstructed = await self.llm_handler.chat(reconstruction_prompt)
        reconstructed = reconstructed.strip()

        logger.info(f"ğŸ”§ ì§ˆì˜ ì¬êµ¬ì„±: '{current_query}' â†’ '{reconstructed}'")
        return reconstructed
