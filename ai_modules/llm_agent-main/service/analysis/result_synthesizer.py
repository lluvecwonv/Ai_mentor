"""
ê²°ê³¼ ì¢…í•©ê¸° - ì—ì´ì „íŠ¸ê°€ ì°¾ì€ ê²°ê³¼ë¥¼ LLMì´ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ìœ¼ë¡œ ë³€í™˜
"""

import logging
import asyncio
from typing import Dict, Any
from utils.prompt_loader import load_prompt
from utils.logging import SynthesisLogger

logger = logging.getLogger(__name__)

class ResultSynthesizer:
    """ì—ì´ì „íŠ¸ ê²°ê³¼ë¥¼ LLMìœ¼ë¡œ ì¢…í•©í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, llm_handler):
        self.llm_handler = llm_handler

    async def synthesize_with_llm(self, user_message: str, found_results: str,
                                 processing_type: str, query_analysis: Dict[str, Any],
                                 conversation_history: str = "") -> str:
        """LLMì„ ì‚¬ìš©í•´ì„œ ì—ì´ì „íŠ¸ê°€ ì°¾ì€ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ìœ¼ë¡œ ì¢…í•© (íˆìŠ¤í† ë¦¬ í¬í•¨)"""
        try:
            # í”„ë¡¬í”„íŠ¸ íŒŒì¼ì—ì„œ í…œí”Œë¦¿ ë¡œë“œ
            synthesis_template = load_prompt("synthesis_prompt")

            # íˆìŠ¤í† ë¦¬ ì„¹ì…˜ êµ¬ì„±
            history_section = ""
            if conversation_history:
                history_section = f"### ì´ì „ ëŒ€í™” ë§¥ë½:\n{conversation_history}\n"
                logger.info(f"ğŸ“š Synthesisì— íˆìŠ¤í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€: {len(conversation_history)}ì")

            # í”„ë¡¬í”„íŠ¸ì— ì‹¤ì œ ê°’ë“¤ ëŒ€ì…
            synthesis_prompt = synthesis_template.format(
                conversation_history=history_section,
                user_message=user_message,
                found_results=found_results,
                processing_type=processing_type
            )

            # LLM í˜¸ì¶œ
            SynthesisLogger.log_synthesis_start(len(synthesis_prompt))

            if self.llm_handler and hasattr(self.llm_handler, 'invoke_simple'):
                # LangChain ë°©ì‹
                synthesized = await self.llm_handler.invoke_simple(synthesis_prompt)
            elif self.llm_handler and hasattr(self.llm_handler, 'chat_completion'):
                # ê¸°ë³¸ chat completion ë°©ì‹
                messages = [{"role": "user", "content": synthesis_prompt}]
                if asyncio.iscoroutinefunction(self.llm_handler.chat_completion):
                    synthesized = await self.llm_handler.chat_completion(messages)
                else:
                    synthesized = await asyncio.get_event_loop().run_in_executor(
                        None, lambda: self.llm_handler.chat_completion(messages)
                    )
            else:
                SynthesisLogger.log_handler_unavailable()
                return found_results

            if isinstance(synthesized, str) and synthesized.strip():
                SynthesisLogger.log_synthesis_success(len(synthesized))
                return synthesized.strip()
            else:
                SynthesisLogger.log_synthesis_empty()
                return found_results

        except Exception as e:
            SynthesisLogger.log_synthesis_error(e)
            return found_results

    def should_synthesize(self, processing_type: str) -> bool:
        """í•´ë‹¹ ì²˜ë¦¬ íƒ€ì…ì— ëŒ€í•´ LLM ì¢…í•©ì´ í•„ìš”í•œì§€ íŒë‹¨"""
        # llm_only, cache_only, curriculum_focusedëŠ” ì¢…í•©í•˜ì§€ ì•ŠìŒ (ì´ë¯¸ ì™„ì „í•œ ë‹µë³€ ìƒì„±ë¨)
        should_synthesize = processing_type not in ['llm_only', 'cache_only', 'curriculum_focused']
        SynthesisLogger.log_should_synthesize_decision(processing_type, should_synthesize)
        return should_synthesize