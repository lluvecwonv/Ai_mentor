"""
Light ë³µì¡ë„ ë…¸ë“œë“¤
ê°„ë‹¨í•œ ì‘ë‹µì´ë‚˜ ì¸ì‚¬ë§ ì²˜ë¦¬
"""

import logging
from typing import Dict, Any
from ..base_node import BaseNode, NodeTimer
from ...handlers.llm_client_main import LlmClient

logger = logging.getLogger(__name__)


class LightNodes(BaseNode):
    """Light ë³µì¡ë„ ì²˜ë¦¬ ë…¸ë“œë“¤"""

    def __init__(self, llm_handler=None):
        self.llm_handler = llm_handler

    async def light_node(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Light ë…¸ë“œ - ê°„ë‹¨í•œ ì§ˆë¬¸, ì¸ì‚¬ë§ ë“± ì²˜ë¦¬"""
        with NodeTimer("Light") as timer:
            # âœ… routerì—ì„œ ì¬êµ¬ì„±ëœ ì¿¼ë¦¬ ì‚¬ìš© (ì—°ì†ëŒ€í™” ì²˜ë¦¬ ì™„ë£Œë¨)
            user_message = state.get("user_message") or state.get("query_for_handlers") or state.get("query", "")

            logger.info(f"ğŸ” [LIGHT] ì‚¬ìš© ì¿¼ë¦¬: '{user_message}'")

            # Light ë…¸ë“œìš© LLM ì„¤ì • (ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ ì‘ì€ ëª¨ë¸ ì‚¬ìš©)
            light_llm = LlmClient.create_with_config(
                model="gpt-4.1",  # ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•œ ì‘ì€ ëª¨ë¸
                max_tokens=400  # ê°„ë‹¨í•œ ì‘ë‹µì„ ìœ„í•œ ì ì€ í† í°
            )

            response = await light_llm.chat(user_message)

            return self.add_step_time(state, {
                "final_result": response,
                "processing_type": "light",
                "complexity": "light"
            }, timer)

