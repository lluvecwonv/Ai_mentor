"""
í†µí•© LangGraph ì•„í‚¤í…ì²˜
Light/Medium/Heavy ë³µì¡ë„ë¥¼ ëª¨ë‘ ì²˜ë¦¬í•˜ëŠ” ë‹¨ì¼ ê·¸ë˜í”„
"""

from __future__ import annotations
import logging
import time
import asyncio
from typing import Dict, Any, List, Literal
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

# ê¸°ì¡´ ì»´í¬ë„ŒíŠ¸ë“¤ import
from processors.router import Router
from handlers import (
    VectorSearchHandler,
    SqlQueryHandler,
    DepartmentMappingHandler,
    CurriculumHandler
)
from service.analysis.result_synthesizer import ResultSynthesizer
from service.analysis.query_analyzer import QueryAnalyzer
from service.core.memory import ConversationMemory

# LangGraph ìƒíƒœ import
from .langgraph_state import UnifiedMentorState, get_user_message, add_step_time
from service.nodes import NodeManager

# ë‹¨ì¼ LLM í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© (ë‹¨ìˆœí™”)
from utils.llm_client_langchain import LlmClientLangChain as LlmClientLangChainAdvanced

logger = logging.getLogger(__name__)

class UnifiedLangGraphApp:
    """í†µí•© LangGraph ì• í”Œë¦¬ì¼€ì´ì…˜"""

    def __init__(self, conversation_memory: ConversationMemory = None):
        """
        í†µí•© ê·¸ë˜í”„ ì´ˆê¸°í™”

        Args:
            conversation_memory: ëŒ€í™” ë©”ëª¨ë¦¬ (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ê³µìœ )
        """
        logger.info("ğŸ—ï¸ í†µí•© LangGraph ì•„í‚¤í…ì²˜ ì´ˆê¸°í™” ì‹œì‘")

        # ê¸°ì¡´ ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™”
        self.query_analyzer = QueryAnalyzer()
        self.conversation_memory = conversation_memory

        # í•¸ë“¤ëŸ¬ë“¤ ì´ˆê¸°í™”
        self.vector_handler = VectorSearchHandler()
        self.sql_handler = SqlQueryHandler()
        self.dept_handler = DepartmentMappingHandler()
        self.curriculum_handler = CurriculumHandler()

        # LLM í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” (ë‹¨ìˆœí™”)
        self.llm_handler = LlmClientLangChainAdvanced()

        # ê²°ê³¼ í•©ì„±ê¸°
        self.result_synthesizer = ResultSynthesizer(self.llm_handler)

        # OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        from openai import OpenAI
        from config.settings import settings
        openai_client = OpenAI(api_key=settings.openai_api_key)

        # NodeManager ì´ˆê¸°í™”
        self.node_manager = NodeManager(
            query_analyzer=self.query_analyzer,
            llm_handler=self.llm_handler,
            sql_handler=self.sql_handler,
            vector_handler=self.vector_handler,
            dept_handler=self.dept_handler,
            curriculum_handler=self.curriculum_handler,
            result_synthesizer=self.result_synthesizer,
            openai_client=openai_client
        )

        # ê·¸ë˜í”„ ë¹Œë“œ
        self.graph = self._build_unified_graph()

        logger.info("âœ… í†µí•© LangGraph ì•„í‚¤í…ì²˜ ì´ˆê¸°í™” ì™„ë£Œ")

    def _build_unified_graph(self) -> StateGraph:
        """í†µí•© ê·¸ë˜í”„ êµ¬ì¡° ìƒì„±"""
        logger.info("ğŸ”§ í†µí•© ê·¸ë˜í”„ êµ¬ì¡° ìƒì„±")

        graph = StateGraph(UnifiedMentorState)

        # NodeManagerë¡œë¶€í„° ëª¨ë“  ë…¸ë“œë“¤ ê°€ì ¸ì˜¤ê¸°
        all_nodes = self.node_manager.get_all_nodes()
        conditional_edges = self.node_manager.get_conditional_edges()

        # ë…¸ë“œë“¤ ì¶”ê°€
        for node_name, node_func in all_nodes.items():
            graph.add_node(node_name, node_func)
            logger.debug(f"  ë…¸ë“œ ì¶”ê°€: {node_name}")

        logger.info(f"âœ… {len(all_nodes)}ê°œ ë…¸ë“œ ì¶”ê°€ ì™„ë£Œ")

        # íë¦„ ì •ì˜
        graph.add_edge(START, "router")

        # ì¡°ê±´ë¶€ ì—£ì§€ë“¤ ì¶”ê°€
        for edge_name, edge_func in conditional_edges.items():
            if edge_name == "route_by_complexity":
                # ë³µì¡ë„ë³„ ë¼ìš°íŒ…
                graph.add_conditional_edges(
                    "router",
                    edge_func,
                    {
                        "light_llm": "light_llm",
                        "light_greeting": "light_greeting",
                        "medium_sql": "medium_sql",
                        "medium_vector": "medium_vector",
                        "medium_curriculum": "medium_curriculum",
                        "medium_agent": "medium_agent",
                        "heavy_sequential": "heavy_sequential"
                    }
                )

        # Light ì²˜ë¦¬ íë¦„
        graph.add_edge("light_llm", "synthesis")
        graph.add_edge("light_greeting", "synthesis")

        # Medium ì²˜ë¦¬ íë¦„
        graph.add_edge("medium_sql", "synthesis")
        graph.add_edge("medium_vector", "synthesis")
        graph.add_edge("medium_curriculum", "synthesis")
        graph.add_edge("medium_agent", "synthesis")

        # Heavy ì²˜ë¦¬ íë¦„ (ìˆœì°¨ ì‹¤í–‰ë§Œ)

        # Heavy ìˆœì°¨ ì²˜ë¦¬ íë¦„
        graph.add_edge("heavy_sequential", "synthesis")

        # í•©ì„± ë° ì™„ë£Œ
        graph.add_edge("synthesis", "finalize")
        graph.add_edge("finalize", END)

        compiled_graph = graph.compile()
        logger.info("âœ… í†µí•© ê·¸ë˜í”„ ì»´íŒŒì¼ ì™„ë£Œ")

        return compiled_graph

    async def process_query(self, user_message: str, session_id: str = "default") -> Dict[str, Any]:
        """í†µí•© ì¿¼ë¦¬ ì²˜ë¦¬"""
        logger.info(f"ğŸš€ í†µí•© ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘: '{user_message[:50]}...'")

        try:
            # ìƒíƒœ ì´ˆê¸°í™”
            initial_state = {
                "messages": [HumanMessage(content=user_message)],
                "session_id": session_id,
                "user_query": user_message,
                "slots": {},
                "step_times": {},
                "retry_count": 0,
                "parallel_tasks": [],
                "processing_type": "unknown",
                "conversation_memory": self.conversation_memory  # ì—°ì†ëŒ€í™” ë¶„ì„ìš©
            }

            # ê·¸ë˜í”„ ì‹¤í–‰
            result = await self.graph.ainvoke(initial_state)

            return {
                "response": result.get("final_result", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"),
                "processing_type": result.get("processing_type", "unknown"),
                "hybrid_info": {
                    "query_analysis": {
                        "complexity": result.get("complexity", "unknown"),
                        "plan": result.get("plan", [])
                    }
                },
                "execution_stats": result.get("execution_stats", {})
            }

        except Exception as e:
            logger.error(f"âŒ í†µí•© ì¿¼ë¦¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "response": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "processing_type": "error",
                "error": str(e)
            }


def create_unified_langgraph_app(conversation_memory: ConversationMemory = None) -> UnifiedLangGraphApp:
    """í†µí•© LangGraph ì•± ìƒì„± íŒ©í† ë¦¬"""
    return UnifiedLangGraphApp(conversation_memory)