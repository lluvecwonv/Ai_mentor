"""
LangGraph ì• í”Œë¦¬ì¼€ì´ì…˜
ë³µì¡ë„ë³„ ì²˜ë¦¬ë¥¼ ìœ„í•œ ê·¸ë˜í”„ êµ¬ì¡°
"""

import logging
from typing import Dict, Any
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, START, END

# í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë§Œ import
from handlers import (
    VectorSearchHandler,
    SqlQueryHandler,
    DepartmentMappingHandler,
    CurriculumHandler,
    QueryAnalyzer,
    ResultSynthesizer,
    LlmClient
)
from ..memory.memory import ConversationMemory
from ..memory.context_analyzer import ConversationContextAnalyzer
from .langgraph_state import GraphState, create_initial_state
from ..nodes import NodeManager


logger = logging.getLogger(__name__)

class LangGraphApp:
    """LangGraph ì• í”Œë¦¬ì¼€ì´ì…˜"""

    def __init__(self, conversation_memory: ConversationMemory = None):
        """
        í†µí•© ê·¸ë˜í”„ ì´ˆê¸°í™”

        Args:
            conversation_memory: ëŒ€í™” ë©”ëª¨ë¦¬ (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ê³µìœ )
        """
        logger.info("ğŸ—ï¸ í†µí•© LangGraph ì•„í‚¤í…ì²˜ ì´ˆê¸°í™” ì‹œì‘")

        # ë©”ëª¨ë¦¬ ì„¤ì •
        self.conversation_memory = conversation_memory

        # LLM í•¸ë“¤ëŸ¬ ìƒì„± (í†µí•© ì‚¬ìš©)
        self.llm_handler = LlmClient()

        # íˆìŠ¤í† ë¦¬ ë¶„ì„ê¸° ì´ˆê¸°í™” (llm_handler ì „ë‹¬)
        self.context_analyzer = ConversationContextAnalyzer(self.llm_handler)

        # NodeManager ì´ˆê¸°í™”
        self.node_manager = NodeManager(
            query_analyzer=QueryAnalyzer(),
            llm_handler=self.llm_handler,  # ê°™ì€ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
            sql_handler=SqlQueryHandler(),
            vector_handler=VectorSearchHandler(),
            dept_handler=DepartmentMappingHandler(),
            curriculum_handler=CurriculumHandler(),
            result_synthesizer=ResultSynthesizer(self.llm_handler)  # ê°™ì€ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
        )

        # ê·¸ë˜í”„ ë¹Œë“œ
        self.graph = self.build_graph()

        logger.info("âœ… í†µí•© LangGraph ì•„í‚¤í…ì²˜ ì´ˆê¸°í™” ì™„ë£Œ")

    def build_graph(self) -> StateGraph:
        """ê·¸ë˜í”„ êµ¬ì¡° ìƒì„±"""
        logger.info("ğŸ”§ ê·¸ë˜í”„ êµ¬ì¡° ìƒì„±")

        graph = StateGraph(GraphState)

        # NodeManagerë¡œë¶€í„° ëª¨ë“  ë…¸ë“œë“¤ ê°€ì ¸ì˜¤ê¸°
        all_nodes = self.node_manager.get_all_nodes()
        conditional_edges = self.node_manager.get_conditional_edges()

        # ë…¸ë“œë“¤ ì¶”ê°€
        for node_name, node_func in all_nodes.items():
            graph.add_node(node_name, node_func)

        logger.info(f"âœ… {len(all_nodes)}ê°œ ë…¸ë“œ ì¶”ê°€ ì™„ë£Œ")

        # íë¦„ ì •ì˜
        graph.add_edge(START, "router")

        # ì¡°ê±´ë¶€ ì—£ì§€ë“¤ ì¶”ê°€
        for edge_name, edge_func in conditional_edges.items():
            if edge_name == "route_by_complexity":
                graph.add_conditional_edges(
                    "router",
                    edge_func,
                    {
                        "light": "light",
                        "medium_sql": "medium_sql",
                        "medium_vector": "medium_vector",
                        "medium_curriculum": "medium_curriculum",
                        "heavy_sequential": "heavy_sequential"
                    }
                )

        # ëª¨ë“  ì²˜ë¦¬ ë…¸ë“œ â†’ synthesis â†’ finalize â†’ END
        for node in ["light", "medium_sql", "medium_vector", "medium_curriculum", "heavy_sequential"]:
            graph.add_edge(node, "synthesis")

        graph.add_edge("synthesis", "finalize")
        graph.add_edge("finalize", END)

        compiled_graph = graph.compile()
        logger.info("âœ… í†µí•© ê·¸ë˜í”„ ì»´íŒŒì¼ ì™„ë£Œ")

        return compiled_graph

    async def process_query(self, user_message: str, session_id: str = "default") -> Dict[str, Any]:
        """í†µí•© ì¿¼ë¦¬ ì²˜ë¦¬ - íˆìŠ¤í† ë¦¬ ë¶„ì„ í¬í•¨"""
        logger.info(f"ğŸš€ í†µí•© ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘: '{user_message[:50]}...'")

        # íˆìŠ¤í† ë¦¬ ë¶„ì„ ìˆ˜í–‰ (context_analyzerì— ì™„ì „ ìœ„ì„)
        history_analysis = await self.context_analyzer.analyze_session_context(
            user_message,
            self.conversation_memory,
            session_id
        )

        # ìƒíƒœ ì´ˆê¸°í™”
        initial_state = create_initial_state(user_message, session_id)
        initial_state["conversation_memory"] = self.conversation_memory
        initial_state["is_continuation"] = history_analysis.get("is_continuation", False)
        initial_state["history_usage"] = history_analysis.get("history_usage", {})

        # ê·¸ë˜í”„ ì‹¤í–‰
        result = await self.graph.ainvoke(initial_state)

        # ì‘ë‹µ ìƒì„±
        response = result.get("final_result", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥ (ë‹¤ìŒ í„´ì„ ìœ„í•´)
        if self.conversation_memory:
            self.conversation_memory.add_exchange(
                session_id=session_id,
                user_message=user_message,
                assistant_response=response
            )
            logger.info(f"ğŸ’¾ ëŒ€í™” ì €ì¥ ì™„ë£Œ: session_id={session_id}")

        return {
            "response": response,
            "complexity": result.get("complexity", "unknown"),
            "is_continuation": result.get("is_continuation", False),
            "history_usage": result.get("history_usage", {})
        }


