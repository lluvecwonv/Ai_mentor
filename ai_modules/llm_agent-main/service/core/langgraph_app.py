"""
LangGraph ì• í”Œë¦¬ì¼€ì´ì…˜
ë³µì¡ë„ë³„ ì²˜ë¦¬ë¥¼ ìœ„í•œ ê·¸ë˜í”„ êµ¬ì¡°
"""

import logging
from typing import Dict, Any
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, START, END

# í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë§Œ import
from handlers import (
    VectorSearchHandler,
    SqlQueryHandler,
    DepartmentMappingHandler,
    CurriculumHandler,
    QueryAnalyzer,
    ResultSynthesizer,
    LlmClient
)
from service.memory.memory import ConversationMemory
from .langgraph_state import GraphState, create_initial_state
from service.nodes import NodeManager

# OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
from openai import OpenAI
from config.settings import settings

logger = logging.getLogger(__name__)

class LangGraphApp:
    """LangGraph ì• í”Œë¦¬ì¼€ì´ì…˜"""

    def __init__(self, conversation_memory: ConversationMemory = None):
        """
        í†µí•© ê·¸ë˜í”„ ì´ˆê¸°í™”

        Args:
            conversation_memory: ëŒ€í™” ë©”ëª¨ë¦¬ (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ê³µìœ )
        """
        logger.info("ğŸ—ï¸ í†µí•© LangGraph ì•„í‚¤í…ì²˜ ì´ˆê¸°í™” ì‹œì‘")

        # ë©”ëª¨ë¦¬ ì„¤ì •
        self.conversation_memory = conversation_memory

        # NodeManager ì´ˆê¸°í™”
        self.node_manager = NodeManager(
            query_analyzer=QueryAnalyzer(),
            llm_handler=LlmClient(),
            sql_handler=SqlQueryHandler(),
            vector_handler=VectorSearchHandler(),
            dept_handler=DepartmentMappingHandler(),
            curriculum_handler=CurriculumHandler(),
            result_synthesizer=ResultSynthesizer(LlmClient())
        )

        # ê·¸ë˜í”„ ë¹Œë“œ
        self.graph = self.build_graph()

        logger.info("âœ… í†µí•© LangGraph ì•„í‚¤í…ì²˜ ì´ˆê¸°í™” ì™„ë£Œ")

    def build_graph(self) -> StateGraph:
        """ê·¸ë˜í”„ êµ¬ì¡° ìƒì„±"""
        logger.info("ğŸ”§ ê·¸ë˜í”„ êµ¬ì¡° ìƒì„±")

        graph = StateGraph(GraphState)

        # NodeManagerë¡œë¶€í„° ëª¨ë“  ë…¸ë“œë“¤ ê°€ì ¸ì˜¤ê¸°
        all_nodes = self.node_manager.get_all_nodes()
        conditional_edges = self.node_manager.get_conditional_edges()

        # ë…¸ë“œë“¤ ì¶”ê°€
        for node_name, node_func in all_nodes.items():
            graph.add_node(node_name, node_func)

        logger.info(f"âœ… {len(all_nodes)}ê°œ ë…¸ë“œ ì¶”ê°€ ì™„ë£Œ")

        # íë¦„ ì •ì˜
        graph.add_edge(START, "router")

        # ì¡°ê±´ë¶€ ì—£ì§€ë“¤ ì¶”ê°€
        for edge_name, edge_func in conditional_edges.items():
            if edge_name == "route_by_complexity":
                graph.add_conditional_edges(
                    "router",
                    edge_func,
                    {
                        "light": "light",
                        "medium_sql": "medium_sql",
                        "medium_vector": "medium_vector",
                        "medium_curriculum": "medium_curriculum",
                        "medium_agent": "medium_agent",
                        "heavy_sequential": "heavy_sequential"
                    }
                )

        # ëª¨ë“  ì²˜ë¦¬ ë…¸ë“œ â†’ synthesis â†’ finalize â†’ END
        for node in ["light", "medium_sql", "medium_vector", "medium_curriculum", "medium_agent", "heavy_sequential"]:
            graph.add_edge(node, "synthesis")

        graph.add_edge("synthesis", "finalize")
        graph.add_edge("finalize", END)

        compiled_graph = graph.compile()
        logger.info("âœ… í†µí•© ê·¸ë˜í”„ ì»´íŒŒì¼ ì™„ë£Œ")

        return compiled_graph

    async def process_query(self, user_message: str, session_id: str = "default") -> Dict[str, Any]:
        """í†µí•© ì¿¼ë¦¬ ì²˜ë¦¬"""
        logger.info(f"ğŸš€ í†µí•© ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘: '{user_message[:50]}...'")

        # ìƒíƒœ ì´ˆê¸°í™”
        initial_state = create_initial_state(user_message, session_id)
        initial_state["conversation_memory"] = self.conversation_memory

        # ê·¸ë˜í”„ ì‹¤í–‰
        result = await self.graph.ainvoke(initial_state)

        return {
            "response": result.get("final_result", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"),
            "complexity": result.get("complexity", "unknown")
        }


