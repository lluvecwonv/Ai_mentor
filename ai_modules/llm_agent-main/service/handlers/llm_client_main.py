from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
import os
import asyncio
import json
import re
import logging

logger = logging.getLogger(__name__)

class LlmClient:
    def __init__(self, model: str = "gpt-4o-mini", max_tokens: int = 4000):
        self.model = model
        self.max_tokens = max_tokens
        self.llm = ChatOpenAI(
            openai_api_key=os.getenv("OPENAI_API_KEY"),
            model=model,
            temperature=0,
            max_tokens=max_tokens
        )

    @classmethod
    def create_with_config(cls, model: str, max_tokens: int):
        """íŠ¹ì • ì„¤ì •ìœ¼ë¡œ ìƒˆë¡œìš´ LlmClient ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        return cls(model=model, max_tokens=max_tokens)

    async def chat(self, message: str, context: str = None, json_mode: bool = False) -> str:
        """ì±„íŒ… ì‘ë‹µ ìƒì„±"""
        # ë©”ì‹œì§€ êµ¬ì„±
        messages = []
        if context:
            messages.append(SystemMessage(content=context))
        messages.append(HumanMessage(content=message))

        # JSON ëª¨ë“œ ì„¤ì •
        llm = self.llm.bind(response_format={"type": "json_object"}) if json_mode else self.llm

        response = await asyncio.get_event_loop().run_in_executor(
            None, llm.invoke, messages
        )
        return response.content

    async def chat_stream(self, message: str, context: str = None):
        """ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì‘ë‹µ ìƒì„±"""
        messages = []
        if context:
            messages.append(SystemMessage(content=context))
        messages.append(HumanMessage(content=message))
        
        # ğŸ”¥ LangChain astream ì‚¬ìš©
        async for chunk in self.llm.astream(messages):
            if hasattr(chunk, 'content') and chunk.content:
                yield chunk.content

    def chat_completion(self, messages, model: str = None, **kwargs) -> str:
        """OpenAI ìŠ¤íƒ€ì¼ chat completion - chat ë©”ì„œë“œë¥¼ ë™ê¸°ë¡œ ë˜í•‘"""
        user_content = ""
        system_content = None

        for msg in messages:
            if msg.get("role") == "system":
                system_content = msg.get("content", "")
            elif msg.get("role") == "user":
                user_content = msg.get("content", "")

        try:
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(self.chat(user_content, system_content))
            loop.close()
            return result
        except Exception as e:
            return f"Error in chat_completion: {str(e)}"

    async def validate_light_query(self, query: str) -> dict:
        """
        Light ë¼ìš°íŒ… ê²€ì¦ - ì§ˆë¬¸ì´ ì •ë§ ì¼ë°˜ ëŒ€í™”ì¸ì§€ í™•ì¸

        Returns:
            {
                "is_general_chat": bool,
                "reason": str,
                "success": bool
            }
        """
        try:
            # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
            prompt_path = os.path.join(
                os.path.dirname(__file__),
                "prompts",
                "light_validator_prompt.txt"
            )

            with open(prompt_path, "r", encoding="utf-8") as f:
                prompt_template = f.read()

            # ì¿¼ë¦¬ ì‚½ì…
            prompt = prompt_template.format(query=query)

            # LLM í˜¸ì¶œ (JSON ëª¨ë“œ)
            response = await self.chat(prompt, json_mode=True)

            logger.info(f"ğŸ” [Light Validator] LLM ì‘ë‹µ: {response}")

            # JSON íŒŒì‹±
            result = json.loads(response)

            return {
                "is_general_chat": result.get("is_general_chat", False),
                "reason": result.get("reason", ""),
                "success": True
            }

        except json.JSONDecodeError as e:
            logger.error(f"âŒ Light Validator JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì •ê·œì‹ìœ¼ë¡œ ì¬ì‹œë„
            try:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    result = json.loads(json_match.group())
                    return {
                        "is_general_chat": result.get("is_general_chat", False),
                        "reason": result.get("reason", ""),
                        "success": True
                    }
            except:
                pass

            # ì™„ì „ ì‹¤íŒ¨ ì‹œ ì•ˆì „í•˜ê²Œ í†µê³¼
            return {
                "is_general_chat": True,
                "reason": "JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ê¸°ë³¸ í†µê³¼",
                "success": False
            }

        except Exception as e:
            logger.error(f"âŒ Light Validator ì‹¤íŒ¨: {e}")
            # ì—ëŸ¬ ì‹œ ì•ˆì „í•˜ê²Œ í†µê³¼
            return {
                "is_general_chat": True,
                "reason": f"ê²€ì¦ ì‹¤íŒ¨: {str(e)}",
                "success": False
            }