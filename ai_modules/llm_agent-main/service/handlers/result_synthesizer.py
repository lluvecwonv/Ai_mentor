import logging
from typing import Dict, Any
from utils.prompt_loader import load_prompt
from .llm_client_main import LlmClient

logger = logging.getLogger(__name__)

class ResultSynthesizer:
    def __init__(self, llm_handler=None):
        self.llm_handler = llm_handler

    async def synthesize_with_llm(self, user_message: str, found_results: str,
                                 processing_type: str) -> str:
        """LLMì„ ì‚¬ìš©í•´ì„œ ì—ì´ì „íŠ¸ê°€ ì°¾ì€ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ìœ¼ë¡œ ì¢…í•©"""
        try:
            # í•©ì„±ìš© LLM ì„¤ì • (ê³ í’ˆì§ˆ í•©ì„±ì„ ìœ„í•´ í° ëª¨ë¸ ì‚¬ìš©)
            synthesis_llm = LlmClient.create_with_config(
                model="gpt-4.1-mini",  # ê³ í’ˆì§ˆ í•©ì„±ì„ ìœ„í•œ í° ëª¨ë¸
                max_tokens=16000  # ê¸´ ì‘ë‹µì„ ìœ„í•œ ë§ì€ í† í°
            )

            # í”„ë¡¬í”„íŠ¸ ë¡œë“œ ë° íˆìŠ¤í† ë¦¬ ì„¹ì…˜ êµ¬ì„±
            synthesis_template = load_prompt("synthesis_prompt")

            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            synthesis_prompt = synthesis_template.format(
                user_message=user_message,
                found_results=found_results,
                processing_type=processing_type,
            )

            logger.info(f"ğŸš€ í•©ì„± ì‹œì‘: prompt_length={len(synthesis_prompt)}")

            # LLM í˜¸ì¶œ (synthesis_llm ì‚¬ìš©)
            synthesized = await synthesis_llm.chat(synthesis_prompt)

            # ê²°ê³¼ ê²€ì¦ ë° ë°˜í™˜
            if isinstance(synthesized, str) and synthesized.strip():
                logger.info(f"âœ… í•©ì„± ì„±ê³µ: result_length={len(synthesized)}")
                return synthesized.strip()
            else:
                logger.warning("âš ï¸ í•©ì„± ê²°ê³¼ ë¹„ì–´ìˆìŒ")
                return found_results

        except Exception as e:
            logger.error(f"âŒ í•©ì„± ì˜¤ë¥˜: {e}")
            return found_results