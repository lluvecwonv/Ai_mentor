"""
ê°„ë‹¨í•œ ê²°ê³¼ í†µí•©ê¸° - OpenAI í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
"""

import logging
from typing import Dict, Any

logger = logging.getLogger(__name__)

class ResultIntegrator:
    """ê°„ë‹¨í•œ ê²°ê³¼ í†µí•©ê¸°"""

    def integrate(self, results: Dict[str, Any], context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ê²°ê³¼ë¥¼ OpenAI í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        processing_type = results.get("processing_type", "unknown")
        logger.info(f"ğŸ“‹ ResultIntegrator ì…ë ¥: processing_type={processing_type}, results_keys={list(results.keys())}")

        # processing_infoì—ì„œë„ í™•ì¸
        if processing_type == "unknown" and "processing_info" in results:
            alt_type = results["processing_info"].get("processing_type", "unknown")
            logger.info(f"ğŸ“‹ processing_infoì—ì„œ ëŒ€ì²´ íƒ€ì… ë°œê²¬: {alt_type}")
            processing_type = alt_type
        
        # í•™ê³¼ í•„í„° ì„¸ì´í”„ê°€ë“œ ì ìš©
        if context and "department_filter" in context:
            dept_whitelist = set(context["department_filter"])
            if dept_whitelist:
                # ê²°ê³¼ì—ì„œ í•™ê³¼ í•„í„°ë§ (ë¬¸ìì—´ ê²°ê³¼ì¸ ê²½ìš°)
                content = self._get_content(results, processing_type)
                if isinstance(content, str) and "ê³¼ëª©ë“¤ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤" in content:
                    # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ì¸ ê²½ìš° ì¶”ê°€ í•„í„°ë§
                    lines = content.split('\n')
                    filtered_lines = []
                    for line in lines:
                        if '**' in line and '**' in line:
                            # ê³¼ëª©ëª…ì´ í¬í•¨ëœ ì¤„ì¸ ê²½ìš° í•™ê³¼ í™•ì¸
                            dept_match = False
                            for dept in dept_whitelist:
                                if dept in line:
                                    dept_match = True
                                    break
                            if dept_match:
                                filtered_lines.append(line)
                        else:
                            filtered_lines.append(line)
                    content = '\n'.join(filtered_lines)
                    logger.info(f"[integrate] í•™ê³¼ í•„í„° ì ìš©: {len(dept_whitelist)}ê°œ í•™ê³¼ë§Œ í—ˆìš©")
                results["final_result"] = content
        
        content = self._get_content(results, processing_type)
        
        # ìƒì„¸ ë¡œê·¸ ì¶œë ¥
        logger.info(f"ğŸ”§ ResultIntegrator ì‹œì‘: processing_type={processing_type}")
        logger.info(f"ğŸ“¥ ì…ë ¥ results í‚¤: {list(results.keys()) if isinstance(results, dict) else type(results)}")
        logger.info(f"ğŸ“¤ ìƒì„±ëœ content íƒ€ì…: {type(content)}, ê¸¸ì´: {len(str(content)) if content else 0}")
        
        # content ë¯¸ë¦¬ë³´ê¸°
        if content and isinstance(content, str):
            # êµìˆ˜ëª… í‘œê¸° ì¼ê´€í™”: "êµìˆ˜: ê¹€í‰" â†’ "êµìˆ˜: ê¹€í‰ êµìˆ˜" (ì´ë¯¸ ì ‘ë¯¸ì‚¬ê°€ ìˆëŠ” ê²½ìš°/ì •ë³´ ì—†ìŒì€ ì œì™¸)
            try:
                import re
                lines = content.split('\n')
                normalized_lines = []
                professor_line_regex = re.compile(r"^(\s*-\s*êµìˆ˜:\s*)(.+?)\s*$")
                for line in lines:
                    m = professor_line_regex.match(line)
                    if m:
                        prefix, name = m.groups()
                        name_stripped = name.strip()
                        if (
                            name_stripped
                            and name_stripped not in ["ì •ë³´ì—†ìŒ", "ì •ë³´ ì—†ìŒ"]
                            and not (name_stripped.endswith("êµìˆ˜") or name_stripped.endswith("êµìˆ˜ë‹˜"))
                        ):
                            line = f"{prefix}{name_stripped} êµìˆ˜"
                    normalized_lines.append(line)
                content = "\n".join(normalized_lines)
            except Exception:
                pass

            if len(content) < 2000:
                logger.info(f"ğŸ“„ Content ì „ì²´: {content}")
            else:
                preview = content[:2000] + "... (ì´ " + str(len(content)) + "ì)"
                logger.info(f"ğŸ“„ Content ì „ì²´: {preview}")
        
        try:
            logger.info(f"FINAL: ì²˜ë¦¬ ìœ í˜•={processing_type}, ì½˜í…ì¸  ê¸¸ì´={len(content) if isinstance(content, str) else 'N/A'}")
        except Exception:
            pass

        # contexts ì •ë³´ ì¶”ì¶œ ë° ë¡œê·¸
        contexts = results.get("contexts", {})
        logger.info(f"ğŸ”— ResultIntegrator contexts: {list(contexts.keys()) if contexts else 'None'}")

        # contexts ë‚´ìš© í™•ì¸
        if contexts:
            for ctx_type, ctx_data in contexts.items():
                ctx_size = len(str(ctx_data)) if ctx_data else 0
                logger.info(f"  - {ctx_type}: {ctx_size} ë¬¸ì ({bool(ctx_data)})")

        return {
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": content
                },
                "finish_reason": "stop"
            }],
            "processing_info": {
                "processing_type": processing_type
            },
            "processing_type": processing_type,  # ì¶”ê°€ í˜¸í™˜ì„±
            "final_result": content,  # ì¶”ê°€ í˜¸í™˜ì„±
            "contexts": contexts
        }

    def _get_content(self, results: Dict[str, Any], processing_type: str) -> str:
        """ì²˜ë¦¬ íƒ€ì…ì— ë”°ë¥¸ ì½˜í…ì¸  ìƒì„±"""
        # ê¸°ë³¸ ì²˜ë¦¬ íƒ€ì…ë“¤
        if processing_type in ["llm_only", "tot", "default", "llm_fallback"]:
            return results.get("final_result", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # íŠ¹í™” ì²˜ë¦¬ íƒ€ì…ë“¤
        elif processing_type == "vector_focused":
            llm_result = results.get("final_result", "")
            return llm_result

        elif processing_type == "sql_focused":
            llm_result = results.get("final_result", "")
            # SQL ê²°ê³¼ê°€ ì—ëŸ¬ì¸ ê²½ìš° LLMì´ ì¢…í•©í•˜ë„ë¡ ê°•ì œ ì‹¤í–‰
            if "Agent stopped due to max iterations" in llm_result or "SQL ì¿¼ë¦¬ ì˜¤ë¥˜" in llm_result:
                logger.warning("SQL ê²°ê³¼ê°€ ì‹¤íŒ¨í–ˆì§€ë§Œ LLM ì¢…í•©ì„ ê°•ì œ ì‹¤í–‰í•©ë‹ˆë‹¤")
                return "ì£„ì†¡í•©ë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            return llm_result

        elif processing_type in ["mapping_focused", "curriculum_focused", "cache_only", "owner_hint_combo"]:
            return results.get("final_result", "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

        # ì—ëŸ¬ ì²˜ë¦¬ íƒ€ì…ë“¤
        elif processing_type == "error":
            error_msg = results.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
            final_result = results.get("final_result", "")
            if final_result:
                return final_result
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ({error_msg})"

        elif processing_type == "error_fallback":
            return results.get("final_result", "ì¼ì‹œì ì¸ ì˜¤ë¥˜ë¡œ ì¸í•´ ê¸°ë³¸ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

        elif processing_type == "unknown_fallback":
            return results.get("final_result", "ìš”ì²­ì„ ì •í™•íˆ ì´í•´í•˜ì§€ ëª»í–ˆì§€ë§Œ ìµœì„ ì˜ ë‹µë³€ì„ ì œê³µí•´ë“œë ¸ìŠµë‹ˆë‹¤.")

        # ì•Œ ìˆ˜ ì—†ëŠ” ì²˜ë¦¬ íƒ€ì… (ìµœí›„ ìˆ˜ë‹¨)
        else:
            final_result = results.get("final_result", "")
            if final_result:
                # final_resultê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
                return final_result
            else:
                # final_resultë„ ì—†ìœ¼ë©´ ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€ ì œê³µ
                logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ì²˜ë¦¬ íƒ€ì…: {processing_type}")
                return "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì— ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì‹œë©´ ë” ë‚˜ì€ ë‹µë³€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."

    def _create_fallback_response(self, error_message: str) -> Dict[str, Any]:
        """í´ë°± ì‘ë‹µ ìƒì„±"""
        return {
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_message}"
                },
                "finish_reason": "stop"
            }],
            "error": error_message,
            "processing_info": {
                "handler": "chain_manager_fallback",
                "processing_type": "error",
                "version": "4.0"
            }
        }
