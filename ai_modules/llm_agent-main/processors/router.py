"""
ê°„ë‹¨í•œ ì¿¼ë¦¬ ë¼ìš°í„° - ì§ì ‘ í•¸ë“¤ëŸ¬ í˜¸ì¶œ ë°©ì‹ (ë§¥ë½ ë¶„ì„ í†µí•©)
"""

import logging
from typing import Dict, Any, List
from utils.json_utils import to_router_decision
# LangGraph ì „ìš© ëª¨ë“œë¡œ ê°„ì†Œí™”
from handlers.curriculum_handler import CurriculumHandler

logger = logging.getLogger(__name__)

class Router:
    """ê°„ë‹¨í•œ ë¼ìš°í„° - í•¸ë“¤ëŸ¬ ì§ì ‘ í˜¸ì¶œ (ë§¥ë½ ë¶„ì„ í†µí•©)"""

    def __init__(self, vector_processor=None, sql_processor=None, mapping_processor=None, llm_processor=None):
        self.vector_processor = vector_processor
        self.sql_processor = sql_processor
        self.mapping_processor = mapping_processor
        self.llm_processor = llm_processor
        # LangGraph ì „ìš© ëª¨ë“œë¡œ ê°„ì†Œí™”
        self.curriculum_handler = CurriculumHandler()

    async def process(self, query_analysis: Dict[str, Any], data: Dict[str, Any]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ì— ë”°ë¼ ë°”ë¡œ ì‹¤í–‰"""
        logger.info(f"ğŸš¨ ë¼ìš°í„° ì²˜ë¦¬ ì‹œì‘: complexity={query_analysis.get('complexity', 'NONE')}")
        complexity = query_analysis.get('complexity', 'medium')

        # plan ìš°ì„ , ì—†ìœ¼ë©´ pipelineë„ í—ˆìš© (í˜¸í™˜)
        pipeline = query_analysis.get('plan') or query_analysis.get('pipeline') or []

        # ê·œì¹™ ê°•í™”: ë³µìˆ˜ ì—ì´ì „íŠ¸ê°€ ëª…ì‹œëœ plan/pipelineì´ë©´ heavyë¡œ ìŠ¹ê²©
        if complexity == 'medium' and isinstance(pipeline, list) and len(pipeline) > 1:
            logger.info("ì¤‘ê°„ ë³µì¡ë„ì´ì§€ë§Œ ë‹¤ë‹¨ê³„ í”Œëœ ê°ì§€ â†’ heavyë¡œ ìŠ¹ê²©")
            complexity = 'heavy'

        # ğŸ” ëª¨ë“  ë³µì¡ë„ì—ì„œ ë§¥ë½ ë¶„ì„ ìˆ˜í–‰ (heavyì—ì„œë§Œ í•˜ë˜ ê²ƒì„ ëª¨ë“  ë ˆë²¨ë¡œ í™•ì¥)
        user_msg = data.get("user_message", "")
        session_id = data.get("session_id", "default")
        conversation_memory = data.get("conversation_memory")
        history_context = ""
        context_analysis = None

        if conversation_memory:
            try:
                recent_exchanges = conversation_memory.get_recent_exchanges(
                    session_id=session_id,
                    limit=3  # ë§¥ë½ ë¶„ì„ì„ ìœ„í•´ 3ê°œê¹Œì§€ í™•ì¸
                )

                if recent_exchanges and self.context_analyzer:
                    # ë§¥ë½ ë¶„ì„ ìˆ˜í–‰
                    context_analysis = await self.context_analyzer.analyze_context_relevance(
                        current_query=user_msg,
                        history=recent_exchanges
                    )

                    logger.info(f"ğŸ” [ë§¥ë½ë¶„ì„] ê²°ê³¼: {context_analysis.get('context_type', 'unknown')}")
                    logger.info(f"ğŸ“š [ë§¥ë½ë¶„ì„] íˆìŠ¤í† ë¦¬ í•„ìš”: {context_analysis.get('needs_history', False)}")
                    logger.info(f"ğŸ’­ [ë§¥ë½ë¶„ì„] ì´ìœ : {context_analysis.get('reasoning', 'N/A')}")

                    # ë§¥ë½ ë¶„ì„ ê²°ê³¼ì— ë”°ë¼ íˆìŠ¤í† ë¦¬ í¬í•¨ ì—¬ë¶€ ê²°ì •
                    if self.context_analyzer.should_include_history(context_analysis):
                        # íˆìŠ¤í† ë¦¬ê°€ í•„ìš”í•œ ê²½ìš°ì—ë§Œ í¬í•¨
                        history_messages = []
                        for exchange in recent_exchanges[-2:]:  # ìµœê·¼ 2ê°œë§Œ
                            if exchange.get('user_message'):
                                history_messages.append(f"ì‚¬ìš©ì: {exchange['user_message']}")
                            if exchange.get('ai_response'):
                                history_messages.append(f"ì–´ì‹œìŠ¤í„´íŠ¸: {exchange['ai_response']}")

                        history_context = "\n".join(history_messages)
                        logger.info(f"âœ… [ì—°ì†ëŒ€í™”] íˆìŠ¤í† ë¦¬ í¬í•¨: {len(history_context)} ë¬¸ì")
                    else:
                        # ì‚¬ìš©ì ë©”ì‹œì§€ ì •ê·œí™” (ì¤„ë°”ê¿ˆ ì œê±°)
                        clean_user_msg = user_msg.replace('\n', ' ').replace('\r', ' ').strip()
                        logger.info(f"ğŸ¯ [ë…ë¦½ì§ˆë¬¸] íˆìŠ¤í† ë¦¬ ì œì™¸: '{clean_user_msg[:50]}...'")
                else:
                    logger.info("ğŸ“­ [ë§¥ë½ë¶„ì„] ì´ì „ ëŒ€í™” ì—†ìŒ")

            except Exception as e:
                logger.warning(f"âš ï¸ [ë§¥ë½ë¶„ì„] ì˜¤ë¥˜: {e}")
                # ì˜¤ë¥˜ ì‹œ ì•ˆì „í•˜ê²Œ ë…ë¦½ì  ì²˜ë¦¬
                context_analysis = {
                    "needs_history": False,
                    "context_type": "independent",
                    "reasoning": f"ë¶„ì„ ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ ì²˜ë¦¬: {str(e)}"
                }

        # íˆìŠ¤í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ dataì— ì¶”ê°€ (ë…ë¦½ì ì¸ ì§ˆë¬¸ì´ ì•„ë‹Œ ê²½ìš°ë§Œ)
        if history_context and context_analysis.get("needs_history", False):
            data = {**data, "history_context": history_context, "context_analysis": context_analysis}

        def _map_owner_hint_to_sequence(owner_hint: str) -> List[str]:
            hint = (owner_hint or '').upper()
            parts = [p.strip() for p in hint.split('+')] if '+' in hint else ([hint] if hint else [])
            seq: List[str] = []
            for p in parts:
                if 'SQL' in p:
                    seq.append('SQL-Agent')
                elif 'FAISS' in p:
                    seq.append('FAISS-Search-Agent')
                elif 'DEPARTMENT' in p:
                    seq.append('Department-Mapping-Agent')
                elif 'LLM' in p:
                    seq.append('LLM-Fallback-Agent')
            return seq or ['LLM-Fallback-Agent']

        # ğŸ§ª ì„ì‹œ í…ŒìŠ¤íŠ¸: Heavy ëª¨ë“œ ê°•ì œ ì‹¤í–‰
        if "ë°ì´í„°ë² ì´ìŠ¤" in data.get("user_message", "") and "ë²¡í„°" in data.get("user_message", ""):
            logger.info("ğŸ§ª í…ŒìŠ¤íŠ¸: Heavy ëª¨ë“œ ê°•ì œ ì‹¤í–‰")
            complexity = 'heavy'
            # plan ê°•ì œ ìƒì„±
            query_analysis['plan'] = [
                {"step": 1, "agent": "Department-Mapping-Agent", "goal": "í•™ê³¼ ì •ë³´ ì¡°íšŒ"},
                {"step": 2, "agent": "FAISS-Search-Agent", "goal": "ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰"}
            ]

        # light -> LLMë§Œ
        if complexity == 'light':
            logger.info("ğŸ’¡ Light ë³µì¡ë„ - LLM ì§ì ‘ ì²˜ë¦¬")
            llm_result = await self.llm_processor.process(data)
            return {"final_result": llm_result, "processing_type": "llm_only"}

        # medium -> ë‹¨ì¼ ì—ì´ì „íŠ¸
        if complexity == 'medium':
            logger.info("ğŸ”§ Medium ë³µì¡ë„ - ë‹¨ì¼ ì—ì´ì „íŠ¸ ì²˜ë¦¬")
            agent = ''
            if isinstance(pipeline, list) and pipeline:
                # ì •ìƒ í”Œëœì´ë©´ ì²« agent ì‚¬ìš©
                first = pipeline[0] if isinstance(pipeline[0], dict) else {}
                agent = first.get('agent', '')
            if not agent:
                # í”Œëœì´ ì—†ìœ¼ë©´ owner_hintë¡œ ë‹¨ì¼ ì—ì´ì „íŠ¸ ê²°ì •
                owner_hint = str(query_analysis.get('owner_hint', ''))
                seq = _map_owner_hint_to_sequence(owner_hint)
                agent = seq[0] if seq else 'LLM-Fallback-Agent'

            if agent == 'FAISS-Search-Agent':
                # ë²¡í„° ê²€ìƒ‰ + LLM
                vector_result = await self.vector_processor.process(data)
                data_with_context = {**data, "search_context": vector_result}
                llm_result = await self.llm_processor.process(data_with_context)
                return {"final_result": llm_result, "processing_type": "vector_focused", "contexts": {"vector": vector_result}}

            elif agent == 'SQL-Agent':
                # SQL + LLM
                sql_result = await self.sql_processor.process(data)
                data_with_context = {**data, "sql_context": sql_result}
                llm_result = await self.llm_processor.process(data_with_context)
                return {"final_result": llm_result, "processing_type": "sql_focused", "contexts": {"sql": sql_result}}

            elif agent == 'Department-Mapping-Agent':
                # í•™ê³¼ ë§¤í•‘ + LLM
                mapping_result = await self.mapping_processor.process(data)
                data_with_context = {**data, "mapping_context": mapping_result}
                llm_result = await self.llm_processor.process(data_with_context)
                return {"final_result": llm_result, "processing_type": "mapping_focused", "contexts": {"mapping": mapping_result}}

            elif agent == 'Curriculum-Agent':
                # ì»¤ë¦¬í˜ëŸ¼ ìƒì„±
                logger.info("ğŸ“ ì»¤ë¦¬í˜ëŸ¼ ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì‹œì‘")
                try:
                    user_message = data.get("user_message", "")
                    session_id = data.get("session_id", "default")

                    curriculum_result = await self.curriculum_handler.handle(
                        user_message=user_message,
                        query_analysis=query_analysis,
                        session_id=session_id,
                        query=user_message
                    )

                    logger.info(f"âœ… ì»¤ë¦¬í˜ëŸ¼ ì²˜ë¦¬ ì™„ë£Œ: {len(curriculum_result)}ì")
                    return {
                        "final_result": curriculum_result,
                        "processing_type": "curriculum_focused",
                        "contexts": {"curriculum": curriculum_result}
                    }

                except Exception as e:
                    logger.error(f"âŒ ì»¤ë¦¬í˜ëŸ¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨ ì‹œ LLM í´ë°±
                    llm_result = await self.llm_processor.process(data)
                    return {"final_result": llm_result, "processing_type": "curriculum_focused"}

            else:
                # LLM í´ë°±
                llm_result = await self.llm_processor.process(data)
                return {"final_result": llm_result, "processing_type": "llm_fallback"}

        # heavy -> ToT
        if complexity == 'heavy':
            logger.info(f"âš¡ Heavy ë³µì¡ë„ ê°ì§€ - ToT ì‹¤í–‰ ì‹œì‘: {query_analysis.get('owner_hint')}")
            try:
                from service.core.tot_service import ToTCoreService, Message
                user_msg = data.get("user_message", "")
                session_id = data.get("session_id", "default")
                conversation_memory = data.get("conversation_memory")

                logger.info(f"ğŸ¯ ToT ì…ë ¥: user_msg='{user_msg[:50]}...', session_id={session_id}")

                # ToTì— processorë“¤ê³¼ conversation_memory ì „ë‹¬
                tot = ToTCoreService(
                    vector_processor=self.vector_processor,
                    sql_processor=self.sql_processor,
                    mapping_processor=self.mapping_processor,
                    llm_processor=self.llm_processor,
                    session_id=session_id,
                    conversation_memory=conversation_memory
                )

                router_decision = to_router_decision(query_analysis or {})
                logger.info(f"ğŸ“‹ ToTì— ì „ë‹¬í•  ë¼ìš°í„° ê²°ì •: {router_decision}")

                # query_analysisì—ì„œ í™•ì¥ í‚¤ì›Œë“œ ì •ë³´ë¥¼ contextë¡œ ì „ë‹¬ (ë§¥ë½ ë¶„ì„ ê²°ê³¼ í¬í•¨)
                context = {
                    "expanded_queries": query_analysis.get("expanded_queries"),
                    "expansion_keywords": query_analysis.get("expansion_keywords"),
                    "expansion_context": query_analysis.get("expansion_context"),
                    "analysis": query_analysis,
                    "history_context": history_context,
                    "context_analysis": context_analysis
                }

                # LLMì´ ì¶”ì¶œí•œ í•™ê³¼ ì •ë³´ë¥¼ contextì— ì „ë‹¬
                entities = query_analysis.get("entities", {})
                extracted_dept = entities.get("department") if entities else None

                if extracted_dept:
                    context["extracted_department"] = extracted_dept
                    logger.info(f"ğŸ« ToT contextì— ì¶”ì¶œëœ í•™ê³¼ ì „ë‹¬: {extracted_dept}")

                result = tot.run_agent(
                    [Message(role="user", content=user_msg)],
                    session_id=session_id,
                    router_decision=router_decision,
                    context=context
                )
                content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
                logger.info(f"âœ… ToT ì‹¤í–‰ ì™„ë£Œ: content ê¸¸ì´={len(content)}")

                # ToT ê²°ê³¼ ì²˜ë¦¬
                if not isinstance(result, dict):
                    result = {"choices": [{"message": {"content": str(result)}}]}

                result["processing_type"] = "tot"
                result["final_result"] = content
                result["tot_context"] = context

                # ToT ì™„ë£Œ í›„ ConversationMemoryì— ê²°ê³¼ ì €ì¥
                if conversation_memory and content:
                    conversation_memory.add_exchange(
                        session_id=session_id,
                        user_message=user_msg,
                        assistant_response=content
                    )
                    logger.info(f"ğŸ’¾ ToT ê²°ê³¼ë¥¼ ConversationMemoryì— ì €ì¥ ì™„ë£Œ")

                return result
            except Exception as e:
                logger.error(f"âŒ ToT ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                import traceback
                logger.error(f"ToT ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
                llm_result = await self.llm_processor.process(data)
                return {"final_result": llm_result, "processing_type": "llm_fallback"}

        # ToTì—ì„œ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ê²½ìš° - LLM í´ë°±ìœ¼ë¡œ ì²˜ë¦¬
        logger.info(f"ğŸ“ ToT ë¯¸ì²˜ë¦¬ ì¼€ì´ìŠ¤ - LLM í´ë°±: complexity={complexity}")
        llm_result = await self.llm_processor.process(data)
        return {"final_result": llm_result, "processing_type": "tot_fallback"}