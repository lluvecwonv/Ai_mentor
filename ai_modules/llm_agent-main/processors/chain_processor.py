"""
ì²´ì¸ í”„ë¡œì„¸ì„œ - ê°„ì†Œí™”ëœ ì²´ì¸ ì²˜ë¦¬ ê´€ë¦¬ì
ëª¨ë“  ë³µì¡í•œ ë¡œì§ì„ ê°œë³„ í”„ë¡œì„¸ì„œë¡œ ìœ„ì„í•˜ê³ , ë‹¨ìˆœí•œ ì¡°ì •ë§Œ ë‹´ë‹¹
"""

import logging
from typing import Dict, Any
# LangGraph ì „ìš© ëª¨ë“œë¡œ ê°„ì†Œí™”
logger = logging.getLogger(__name__)

from .router import Router
from .vector_processor import VectorProcessor
from .sql_processor import SqlProcessor
from .llm_processor import LlmProcessor
from .mapping_processor import MappingProcessor
from .result_integrator import ResultIntegrator

# LangGraph ì „ìš© ëª¨ë“œë¡œ ê°„ì†Œí™” - ToT ì œê±°

class ChainProcessor:
    """ê°„ì†Œí™”ëœ ì²´ì¸ í”„ë¡œì„¸ì„œ - ë³µì¡í•œ ë¡œì§ì€ ê°œë³„ í”„ë¡œì„¸ì„œê°€ ë‹´ë‹¹"""

    def __init__(self, query_analyzer, conversation_memory, llm_handler,
                 vector_handler, sql_handler, mapping_handler, settings=None):
        # LangGraph ì „ìš© ëª¨ë“œë¡œ ê°„ì†Œí™”

        # ê°œë³„ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        self.vector_processor = VectorProcessor(vector_handler)
        self.sql_processor = SqlProcessor(sql_handler, conversation_memory)
        self.mapping_processor = MappingProcessor(mapping_handler)
        self.llm_processor = LlmProcessor(llm_handler, settings)
        
        # LangGraph ì „ìš© ëª¨ë“œë¡œ ê°„ì†Œí™”
        
        # ë¼ìš°í„°ì— í”„ë¡œì„¸ì„œ ì˜ì¡´ì„± ì£¼ì…
        self.router = Router(
            vector_processor=self.vector_processor,
            sql_processor=self.sql_processor,
            mapping_processor=self.mapping_processor,
            llm_processor=self.llm_processor
        )
        self.result_integrator = ResultIntegrator()

        # ê¸°ì¡´ ì»´í¬ë„ŒíŠ¸ë“¤ (í˜¸í™˜ì„± ìœ ì§€)
        self.query_analyzer = query_analyzer
        self.conversation_memory = conversation_memory
        self.llm_handler = llm_handler

        logger.debug("ChainProcessor ì´ˆê¸°í™” ì™„ë£Œ - ëª¨ë“ˆí˜• ì•„í‚¤í…ì²˜")

    async def execute_with_context(
        self,
        resolved_query: str,
        query_analysis: Dict[str, Any],
        context: Dict[str, Any],
        session_id: str
    ) -> Dict[str, Any]:
        """
        ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ì²´ì¸ ì‹¤í–‰

        Args:
            resolved_query: LLMì´ ì´í•´í•œ í•´ê²°ëœ ì¿¼ë¦¬
            query_analysis: ì¿¼ë¦¬ ë¶„ì„ ê²°ê³¼
            context: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            session_id: ì„¸ì…˜ ID

        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        try:
            # ë°ì´í„° êµ¬ì¡° ì¤€ë¹„
            data = {
                "user_message": resolved_query,
                "analysis": query_analysis,
                "context": context,
                "session_id": session_id,
                "conversation_memory": self.conversation_memory
            }

            # ê¸°ì¡´ process ë©”ì„œë“œ í™œìš©
            result = await self.process(data)

            # OpenAI í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            if not result.get("choices"):
                content = result.get("result", "ì²˜ë¦¬ ì™„ë£Œ")
                result = {
                    "choices": [{
                        "index": 0,
                        "message": {
                            "role": "assistant",
                            "content": content
                        },
                        "finish_reason": "stop"
                    }]
                }

            return result

        except Exception as e:
            logger.error(f"ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "choices": [{
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    },
                    "finish_reason": "error"
                }]
            }

    async def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ - ë¼ìš°íŒ… â†’ ì‹¤í–‰ â†’ í†µí•© (ì§ì ‘ ì‹¤í–‰)"""
        # async with self.performance_tracker.measure_time_async("total_processing"):
        try:
            # 1) ë¶„ì„ í›„ ë°”ë¡œ ì‹¤í–‰
            query_analysis = data.get("analysis", data.get("pre_analysis", {}))
            logger.info(f"ì²´ì¸ ì²˜ë¦¬ ì‹œì‘: {query_analysis.get('complexity')}")

            # ConversationMemoryë¥¼ ë°ì´í„°ì— í¬í•¨
            data_with_memory = {
                **data,
                "conversation_memory": self.conversation_memory
            }

            results = await self.router.process(query_analysis, data_with_memory)

            # 2) ê²°ê³¼ ê²€ì¦ ë° í†µí•©
            if results is None:
                logger.error("ë¼ìš°í„°ê°€ Noneì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
                results = {
                    "processing_type": "error",
                    "result": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                    "error": "router returned None"
                }

            logger.info(f"ğŸ”§ ë¼ìš°í„° ê²°ê³¼: {results.get('processing_type')} (í‚¤: {list(results.keys()) if isinstance(results, dict) else type(results)})")

            # ToT ê²°ê³¼ì¸ ê²½ìš° ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì—¬ í†µí•©
            if results.get('processing_type') == 'tot':
                tot_context = results.get('tot_context', {})

                # ToTê°€ ì‹¤í–‰í•œ ê° í”„ë¡œì„¸ì„œë“¤ì˜ ê²°ê³¼ë¥¼ contextsë¡œ ìˆ˜ì§‘
                contexts = results.get('contexts', {})
                if not contexts:
                    # contextsê°€ ì—†ìœ¼ë©´ tot_contextì—ì„œ ì¶”ì¶œ ì‹œë„
                    contexts = {
                        "sql": tot_context.get('sql_context', tot_context.get('sql', "")),
                        "vector": tot_context.get('vector_context', tot_context.get('vector', "")),
                        "mapping": tot_context.get('mapping_context', tot_context.get('mapping', "")),
                        "tot_raw": tot_context
                    }
                    results['contexts'] = contexts  # ToT ê²°ê³¼ì— contexts ì¶”ê°€

                logger.info(f"ğŸ« ToT contexts í™•ì¸: sql={bool(contexts.get('sql'))}, vector={bool(contexts.get('vector'))}, mapping={bool(contexts.get('mapping'))}")
                logger.info(f"ğŸ« ToT context department_filter: {tot_context.get('department_filter', 'None')}")

                # í†µí•© ì‹œ contextsì™€ tot_context ëª¨ë‘ ì „ë‹¬
                final_response = self.result_integrator.integrate(results, tot_context)
            else:
                final_response = self.result_integrator.integrate(results)
            
            # ìµœì¢… ì‘ë‹µ ìƒì„¸ ë¡œê·¸
            logger.info(f"âœ… ì²´ì¸ ì²˜ë¦¬ ì™„ë£Œ: {final_response.get('processing_type')}")
            logger.info(f"ğŸ“‹ ìµœì¢… ì‘ë‹µ êµ¬ì¡°: {list(final_response.keys()) if isinstance(final_response, dict) else type(final_response)}")
            
            # choices ìƒì„¸ ì •ë³´
            if isinstance(final_response, dict) and 'choices' in final_response:
                choices = final_response.get('choices', [])
                logger.info(f"ğŸ“ ìµœì¢… Choices ìˆ˜: {len(choices)}")
                for i, choice in enumerate(choices):
                    if isinstance(choice, dict):
                        message = choice.get('message', {})
                        content = message.get('content', '')
                        logger.info(f"  ìµœì¢… Choice {i}: content_length={len(str(content))}")
                        if content and len(str(content)) < 2000:
                            logger.info(f"    Content: {content}")
                        else:
                            preview = str(content)[:2000] + "... (ì´ " + str(len(str(content))) + "ì)" if len(str(content)) > 2000 else str(content)
                            logger.info(f"    Content: {preview}")
            
            return final_response
        except Exception as e:
            logger.error(f"ì²´ì¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self.result_integrator._create_fallback_response(str(e))



    def get_stats(self) -> Dict[str, Any]:
        """ì „ì²´ í†µê³„ ì¡°íšŒ"""
        return {
            "chain_manager": self.performance_tracker.get_performance_stats(),
            "router": {
                "available_routes": list(self.router.route_map.keys()),
                "total_routes": len(self.router.route_map)
            },
            "processors": {
                "vector": self.vector_processor.get_stats(),
                "sql": self.sql_processor.get_stats(),
                "llm": self.llm_processor.get_stats()
            }
        }

    # ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„± ìœ ì§€
    @property
    def main_chain(self):
        """ê¸°ì¡´ main_chain ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„±"""
        class ChainInterface:
            def __init__(self, manager):
                self.manager = manager

            async def ainvoke(self, input_data):
                return await self.manager.process(input_data)

        return ChainInterface(self)
