import uvicorn
import re
import logging
import logging.config
from pathlib import Path
from contextlib import asynccontextmanager

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

from config.settings import settings, LOGGING_CONFIG
from controller.agentController import router as agent_router

from service.core.mentor_service import HybridMentorService

# ë¡œê·¸ ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„± (í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
log_dir = Path("./logs")
log_dir.mkdir(parents=True, exist_ok=True)

# ì»¤ìŠ¤í…€ ë¡œê¹… ì„¤ì • ì ìš© (ì¼ì‹œì ìœ¼ë¡œ ë¹„í™œì„±í™”)
# logging.config.dictConfig(LOGGING_CONFIG)
logging.basicConfig(level=logging.INFO)

logger = logging.getLogger(__name__)

# ì„œë²„ ì‹œì‘ ì‹œ ë¡œê·¸ ê¸°ë¡
logger.info("ğŸš€ AI Mentor Service ì‹œì‘ - ë¡œê·¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
logger.debug(f"ğŸ“ ë¡œê·¸ ë””ë ‰í† ë¦¬: {log_dir}")
logger.info("=" * 50)

# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ (ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸°í™”)
global_mentor_service = None

@asynccontextmanager
async def lifespan(_: FastAPI):
    """ì„œë²„ ì‹œì‘ ë° ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” lifespan ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬"""
    # Startup
    global global_mentor_service
    logger.info("ğŸš€ ì„œë²„ ì‹œì‘ - í•¸ë“¤ëŸ¬ ì›Œë°ì—… ì‹œì‘")
    # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (í†µí•© LangGraph ëª¨ë“œë¡œ ì´ˆê¸°í™”)
    global_mentor_service = HybridMentorService(use_unified_langgraph=True)

    # ì›Œë°ì—… ì™„ë£Œ í™•ì¸
    warmup_status = global_mentor_service.get_health_status()

    if warmup_status.get("status") == "healthy":
        logger.info("âœ… ì„œë²„ ì‹œì‘ - ëª¨ë“  í•¸ë“¤ëŸ¬ ì›Œë°ì—… ì™„ë£Œ")
    else:
        logger.warning(f"âš ï¸ ì›Œë°ì—… ë¶€ë¶„ ì‹¤íŒ¨: {warmup_status}")

    yield  # ì„œë²„ ì‹¤í–‰ ì¤‘

    # Shutdown
    logger.info("ì„œë²„ ì¢…ë£Œ")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="AI Mentor Service",
    description="LangGraph ê¸°ë°˜ ì§€ëŠ¥í˜• AI ë©˜í† ë§ ì‹œìŠ¤í…œ",
    version="3.0-improved",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# CORS ë¯¸ë“¤ì›¨ì–´
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ë¼ìš°í„° ë“±ë¡
app.include_router(agent_router, tags=["AI Mentor"])

# OpenAI API í˜¸í™˜ ì—”ë“œí¬ì¸íŠ¸
@app.get("/v1/models")
@app.get("/models")
async def get_models():
    """OpenAI API í˜¸í™˜ ëª¨ë¸ ëª©ë¡"""
    return {
        "object": "list",
        "data": [{
            "id": "ai-mentor",
            "object": "model",
            "owned_by": "ai-mentor",
            "name": "ì „ë¶ëŒ€í•™êµ AI Mentor",
            "info": {
                "meta": {
                    "name": "ì „ë¶ëŒ€í•™êµ AI Mentor",
                    "description": "ì „ë¶ëŒ€í•™êµ í•™ì‚¬ ì •ë³´ ë° ì»¤ë¦¬í˜ëŸ¼ ì•ˆë‚´ë¥¼ ë„ì™€ë“œë¦½ë‹ˆë‹¤"
                }
            }
        }]
    }


# Ollama í˜¸í™˜ API (OpenWebUI ìë™ ì¸ì‹ìš©)
@app.get("/api/tags")
async def get_ollama_tags():
    """Ollama í˜¸í™˜ ëª¨ë¸ ëª©ë¡ - OpenWebUIê°€ ìë™ìœ¼ë¡œ ì¸ì‹"""
    return {
        "models": [{
            "name": "ai-mentor",
            "model": "ai-mentor",
            "modified_at": "2025-01-01T00:00:00Z",
            "size": 0,
            "digest": "ai-mentor-digest",
            "details": {
                "format": "gguf",
                "family": "ai-mentor",
                "parameter_size": "7B",
                "quantization_level": "Q4_0"
            }
        }]
    }


@app.post("/api/v2/agent")
async def agent_v2(request: Request):
    """AI Mentor Agent API v2 (íŒŒì´í”„ë¼ì¸ìš©)"""
    try:
        data = await request.json()
        messages = data.get("messages", [])
        session_id = data.get("session_id", "default")
        model = data.get("model", "ai-mentor")

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
        user_message = "\n".join(msg.get("content", "") for msg in messages if msg.get("role") == "user")

        if not user_message.strip():
            return JSONResponse(status_code=400, content={"error": "No user message provided"})

        # AI Mentor ì„œë¹„ìŠ¤ í˜¸ì¶œ (ì„¸ì…˜ ID ì „ë‹¬)
        global global_mentor_service
        response = await global_mentor_service.run_agent(user_message.strip(), session_id)

        # OpenAI í˜•ì‹ ì‘ë‹µ ë°˜í™˜
        return response

    except Exception as e:
        logger.error(f"Agent v2 ì˜¤ë¥˜: {e}")
        return JSONResponse(status_code=500, content={"error": str(e)})


@app.post("/v1/chat/completions")
@app.post("/chat/completions")
async def chat_completions(request: Request):
    """OpenAI API í˜¸í™˜ ì±„íŒ… ì™„ì„±"""
    try:
        data = await request.json()
        messages = data.get("messages", [])

        # ğŸ”¥ chat_idë¥¼ session_idë¡œ ìš°ì„  ì‚¬ìš© (ê° ì±„íŒ…ë§ˆë‹¤ ë…ë¦½ì ì¸ ì„¸ì…˜)
        chat_id = data.get("chat_id")
        session_id = chat_id if chat_id else data.get("session_id", "default")

        logger.info(f"ğŸ“Œ ì±„íŒ… ìš”ì²­ - chat_id: {chat_id}, session_id: {session_id}")

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
        user_message = "\n".join(msg.get("content", "") for msg in messages if msg.get("role") == "user")

        if not user_message.strip():
            return JSONResponse(status_code=400, content={"error": "No user message provided"})

        # AI Mentor ì„œë¹„ìŠ¤ í˜¸ì¶œ (ì„¸ì…˜ ID ì „ë‹¬)
        global global_mentor_service
        response = await global_mentor_service.run_agent(user_message.strip(), session_id)

        # ì‘ë‹µì´ ì´ë¯¸ dict í˜•íƒœì¸ì§€ í™•ì¸í•˜ê³  contentë§Œ ì¶”ì¶œ
        if isinstance(response, dict) and 'choices' in response:
            content = response['choices'][0]['message']['content']
        else:
            content = str(response)

        # OpenAI í˜•ì‹ ì‘ë‹µ
        return {
            "id": "chatcmpl-ai-mentor",
            "object": "chat.completion",
            "model": "ai-mentor",
            "choices": [{
                "index": 0,
                "message": {"role": "assistant", "content": content},
                "finish_reason": "stop"
            }]
        }

    except Exception as e:
        logger.error(f"ì±„íŒ… ì™„ì„± ì˜¤ë¥˜: {e}")
        return JSONResponse(status_code=500, content={"error": str(e)})


# ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def root():
    """ì„œë¹„ìŠ¤ ì •ë³´"""
    return {
        "service": "AI Mentor Service",
        "version": "3.0",
        "status": "running",
        "docs": "/docs"
    }

@app.get("/health")
async def health_check():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    try:
        global global_mentor_service
        if global_mentor_service:
            health_status = global_mentor_service.get_health_status()
            return {"status": "healthy", **health_status}
        else:
            return {"status": "starting"}
    except Exception as e:
        logger.error(f"í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {e}")
        return {"status": "unhealthy", "error": str(e)}


if __name__ == "__main__":
    logger.info(f"AI Mentor Service v3.0-improved ì‹œì‘")
    logger.info(f"í¬íŠ¸: {settings.port}")
    logger.info(f"ë””ë²„ê·¸ ëª¨ë“œ: {settings.debug}")
    logger.info(f"ğŸš€ ì„œë²„ ì‹œì‘ ì‹œ ìë™ ì›Œë°ì—… í™œì„±í™”")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=settings.port,
        log_level=settings.log_level.lower(),
        reload=settings.debug,
        log_config=None,
        access_log=False
    )
