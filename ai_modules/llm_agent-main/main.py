import uvicorn
import re
import logging
import logging.config
from pathlib import Path
from contextlib import asynccontextmanager

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

from config.settings import settings, LOGGING_CONFIG
from controller.agentController import router as agent_router

from service.core.mentor_service import HybridMentorService

# ë¡œê·¸ ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
log_dir = Path("/home/dbs0510/AiMentor_edit/ai_modules/llm_agent-main/logs")
log_dir.mkdir(exist_ok=True)

# ì»¤ìŠ¤í…€ ë¡œê¹… ì„¤ì • ì ìš©
logging.config.dictConfig(LOGGING_CONFIG)

logger = logging.getLogger(__name__)

# ì„œë²„ ì‹œì‘ ì‹œ ë¡œê·¸ ê¸°ë¡
logger.info("ğŸš€ AI Mentor Service ì‹œì‘ - ë¡œê·¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
logger.debug(f"ğŸ“ ë¡œê·¸ ë””ë ‰í† ë¦¬: {log_dir}")
logger.info("=" * 50)

# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ (ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸°í™”)
global_mentor_service = None

@asynccontextmanager
async def lifespan(_: FastAPI):
    """ì„œë²„ ì‹œì‘ ë° ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” lifespan ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬"""
    # Startup
    global global_mentor_service
    logger.info("ğŸš€ ì„œë²„ ì‹œì‘ - í•¸ë“¤ëŸ¬ ì›Œë°ì—… ì‹œì‘")
    # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (í†µí•© LangGraph ëª¨ë“œë¡œ ì´ˆê¸°í™”)
    global_mentor_service = HybridMentorService(use_unified_langgraph=True)

    # ì›Œë°ì—… ì™„ë£Œ í™•ì¸
    warmup_status = global_mentor_service.get_health_status()

    if warmup_status.get("status") == "healthy":
        logger.info("âœ… ì„œë²„ ì‹œì‘ - ëª¨ë“  í•¸ë“¤ëŸ¬ ì›Œë°ì—… ì™„ë£Œ")
    else:
        logger.warning(f"âš ï¸ ì›Œë°ì—… ë¶€ë¶„ ì‹¤íŒ¨: {warmup_status}")


    # Shutdown
    logger.info("ì„œë²„ ì¢…ë£Œ")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="AI Mentor Service",
    description="LangGraph ê¸°ë°˜ ì§€ëŠ¥í˜• AI ë©˜í† ë§ ì‹œìŠ¤í…œ",
    version="3.0-improved",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# CORS ë¯¸ë“¤ì›¨ì–´
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ë¼ìš°í„° ë“±ë¡
app.include_router(agent_router, tags=["AI Mentor"])

# OpenAI API í˜¸í™˜ ì—”ë“œí¬ì¸íŠ¸
@app.get("/v1/models")
async def get_models():
    """OpenAI API í˜¸í™˜ ëª¨ë¸ ëª©ë¡"""
    return {
        "object": "list",
        "data": [{
            "id": "ai-mentor",
            "object": "model",
            "owned_by": "ai-mentor"
        }]
    }


@app.post("/v1/chat/completions")
async def chat_completions(request: Request):
    """OpenAI API í˜¸í™˜ ì±„íŒ… ì™„ì„±"""
    try:
        data = await request.json()
        messages = data.get("messages", [])

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
        user_message = "\n".join(msg.get("content", "") for msg in messages if msg.get("role") == "user")

        if not user_message.strip():
            return JSONResponse(status_code=400, content={"error": "No user message provided"})

        # AI Mentor ì„œë¹„ìŠ¤ í˜¸ì¶œ
        global global_mentor_service
        response = await global_mentor_service.run_agent(user_message.strip())

        # OpenAI í˜•ì‹ ì‘ë‹µ
        return {
            "id": "chatcmpl-ai-mentor",
            "object": "chat.completion",
            "model": "ai-mentor",
            "choices": [{
                "index": 0,
                "message": {"role": "assistant", "content": str(response)},
                "finish_reason": "stop"
            }]
        }

    except Exception as e:
        logger.error(f"ì±„íŒ… ì™„ì„± ì˜¤ë¥˜: {e}")
        return JSONResponse(status_code=500, content={"error": str(e)})


# ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def root():
    """ì„œë¹„ìŠ¤ ì •ë³´"""
    return {
        "service": "AI Mentor Service",
        "version": "3.0",
        "status": "running",
        "docs": "/docs"
    }

@app.get("/health")
async def health_check():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    try:
        global global_mentor_service
        if global_mentor_service:
            health_status = global_mentor_service.get_health_status()
            return {"status": "healthy", **health_status}
        else:
            return {"status": "starting"}
    except Exception as e:
        logger.error(f"í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {e}")
        return {"status": "unhealthy", "error": str(e)}


if __name__ == "__main__":
    logger.info(f"AI Mentor Service v3.0-improved ì‹œì‘")
    logger.info(f"í¬íŠ¸: {settings.port}")
    logger.info(f"ë””ë²„ê·¸ ëª¨ë“œ: {settings.debug}")
    logger.info(f"ğŸš€ ì„œë²„ ì‹œì‘ ì‹œ ìë™ ì›Œë°ì—… í™œì„±í™”")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=settings.port,
        log_level=settings.log_level.lower(),
        reload=settings.debug,
        log_config=None,
        access_log=False
    )
