"""
Vector Search Handler for FAISS-based course search via HTTP
"""

import httpx
import asyncio
from .base_handler import BaseQueryHandler
from config.settings import settings
from typing import Dict, Any, Optional

class VectorSearchHandler(BaseQueryHandler):
    """FAISS ë²¡í„° ê²€ìƒ‰ ì—ì´ì „íŠ¸ - ì „ë¶ëŒ€í•™êµ ê³¼ëª© ê²€ìƒ‰ ì „ìš©

    ì´ ì—ì´ì „íŠ¸ëŠ” ë‹¤ìŒ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
    - ê³¼ëª©ëª…, ê³¼ëª© ë‚´ìš©, ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì˜ë¯¸ì  ê²€ìƒ‰
    - í•™ê³¼ í•„í„°ë§ê³¼ ê²°í•©ëœ ê³¼ëª© ê²€ìƒ‰ (SQL ì‚¬ì „ í•„í„°ë§ ì§€ì›)
    - êµìˆ˜ëª…, ê°•ì˜ì‹¤, ì‹œê°„í‘œ ë“± ê³¼ëª© ìƒì„¸ ì •ë³´ ì œê³µ

    ì£¼ìš” ì‚¬ìš© ì‚¬ë¡€:
    - "ì¸ê³µì§€ëŠ¥ ê´€ë ¨ ìˆ˜ì—… ì°¾ì•„ì¤˜"
    - "ë¨¸ì‹ ëŸ¬ë‹ ê³¼ëª© ì¶”ì²œí•´ì¤˜"
    - "ì»´ê³µì—ì„œ í”„ë¡œê·¸ë˜ë° ìˆ˜ì—…"
    - "ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤ ê´€ë ¨ ê°•ì˜"
    """

    def __init__(self):
        super().__init__()
        # httpx í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        limits = httpx.Limits(max_keepalive_connections=10, max_connections=50)
        transport = httpx.AsyncHTTPTransport(retries=2)
        self.http_client = httpx.AsyncClient(
            timeout=httpx.Timeout(connect=5.0, read=30.0, write=10.0, pool=30.0),
            limits=limits,
            transport=transport,
            headers={"Connection": "keep-alive"}
        )
        # FAISS ê²€ìƒ‰ ì„œë¹„ìŠ¤ URL (LLM ê¸°ë°˜ SQL ì‚¬ì „ í•„í„°ë§ í¬í•¨)
        self.faiss_service_url = f"{settings.search_service_url}-sql-filter"
        self._warmed_up: bool = False
        self._warmup_lock = asyncio.Lock()

    async def warmup(self) -> None:
        """Vector ì„œë¹„ìŠ¤ì— ê°€ë²¼ìš´ ìš”ì²­ì„ ë³´ë‚´ ì»¤ë„¥ì…˜/ì„œë¹„ìŠ¤ë¥¼ ì˜ˆì—´í•©ë‹ˆë‹¤."""
        if self._warmed_up:
            return
        async with self._warmup_lock:
            if self._warmed_up:
                return
            try:
                self.logger.info("ğŸ”¥ Vector Search í•¸ë“¤ëŸ¬ ì›Œë°ì—… ì‹œì‘")
                payload = {"query": "í…ŒìŠ¤íŠ¸", "count": 1}

                response = await self.http_client.post(self.faiss_service_url, json=payload)

                if response.status_code == 200:
                    self.logger.info("âœ… Vector Search í•¸ë“¤ëŸ¬ ì›Œë°ì—… ì™„ë£Œ")
                else:
                    self.logger.warning(f"Vector Search ì›Œë°ì—… ì‘ë‹µ ì˜¤ë¥˜: status={response.status_code}")

                self._warmed_up = True

            except Exception as e:
                # ì›Œë°ì—… ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•ŠìŒ
                self.logger.warning(f"Vector Search ì›Œë°ì—… ì¤‘ ê²½ê³ : {e}")

    def is_available(self) -> bool:
        """Check if vector search service is available"""
        return self.http_client is not None

    async def handle(self, user_message: str, query_analysis: Dict, **kwargs) -> str:
        """Handle vector search query via HTTP"""
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ” FAISS ë²¡í„° ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì‹œì‘")
        self.logger.info(f"ğŸ“¥ ì‚¬ìš©ì ì§ˆë¬¸: {user_message}")
        self.logger.info(f"ğŸ“Š ì¿¼ë¦¬ ë¶„ì„ ë°ì´í„°: {query_analysis}")
        self.logger.info(f"ğŸ”§ ì¶”ê°€ ì¸ì: {kwargs}")

        if not self.is_available():
            self.logger.error("âŒ ë²¡í„° ê²€ìƒ‰ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ")
            return self.get_fallback_message()

        try:
            # ì›Œë°ì—…ì´ ì•„ì§ ì•ˆëœ ê²½ìš°, ë¨¼ì € ì›Œë°ì—… ì‹¤í–‰
            if not self._warmed_up:
                self.logger.info("ğŸ”¥ ë²¡í„° ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì›Œë°ì—… ì‹¤í–‰")
                await self.warmup()

            # ê¸°ë³¸ ì¿¼ë¦¬ í…ìŠ¤íŠ¸: ì‚¬ìš©ì ì›ë¬¸
            query_text = user_message
            self.logger.info(f"ğŸ“ ê¸°ë³¸ ì¿¼ë¦¬ í…ìŠ¤íŠ¸: '{query_text}'")

            # êµìˆ˜ëª… ì¶”ì¶œ (ì „ì²´ ìŠ¤ì½”í”„ì—ì„œ ì‚¬ìš©)
            import re
            professor_pattern = r'([ê°€-í£]{2,4})\s*êµìˆ˜'
            prof_matches = re.findall(professor_pattern, user_message)
            if prof_matches:
                self.logger.info(f"ğŸ‘¨â€ğŸ« êµìˆ˜ëª… ì¶”ì¶œ: {prof_matches}")
            else:
                self.logger.info("ğŸ‘¨â€ğŸ« êµìˆ˜ëª… ì—†ìŒ")

            # í™•ì¥ ì¿¼ë¦¬ë¥¼ ì—°ê²°ëœ ë‹¨ì¼ ì¿¼ë¦¬ë¡œ ë³€í™˜
            expanded_queries = query_analysis.get('expanded_queries') if isinstance(query_analysis, dict) else None
            self.logger.info(f"ğŸ” í™•ì¥ ì¿¼ë¦¬ ë¶„ì„ ê²°ê³¼: {expanded_queries}")

            # ì—°ê²°ëœ ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ìƒì„±
            concatenated_query = query_text
            keywords_used = []

            if expanded_queries:
                self.logger.info(f"ğŸ”— í™•ì¥ ì¿¼ë¦¬ë¥¼ ì—°ê²°ëœ ë‹¨ì¼ ì¿¼ë¦¬ë¡œ ë³€í™˜: {len(expanded_queries)}ê°œ ì¿¼ë¦¬")

                # base ì¿¼ë¦¬ ì œì™¸í•˜ê³  í‚¤ì›Œë“œë“¤ë§Œ ì¶”ì¶œ
                for eq in expanded_queries:
                    kind = eq.get('kind', 'unknown')
                    text = eq.get('text', '').strip()

                    if kind != 'base' and text and text not in concatenated_query:
                        keywords_used.append(text)
                        self.logger.info(f"  ğŸ“ í‚¤ì›Œë“œ ì¶”ê°€: '{text}' (ì¢…ë¥˜: {kind})")

                # ê¸°ë³¸ ì¿¼ë¦¬ì— í‚¤ì›Œë“œë“¤ì„ ì—°ê²°
                if keywords_used:
                    concatenated_query = f"{query_text} {' '.join(keywords_used)}"
                    self.logger.info(f"âœ… ì—°ê²°ëœ ì¿¼ë¦¬ ìƒì„±: '{concatenated_query}'")

            else:
                self.logger.info("ğŸ”„ í™•ì¥ ì¿¼ë¦¬ ìƒì„± - expansion_keywords ê¸°ë°˜")
                # fallback: expansion_keywordsë¡œ ê°„ë‹¨ ìƒì„±
                kw_raw = str(query_analysis.get('expansion_keywords', '') or '') if isinstance(query_analysis, dict) else ''
                kws = [k.strip() for k in kw_raw.split(',') if k.strip()]
                self.logger.info(f"ğŸ“‹ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {kws}")

                # êµìˆ˜ëª…ì„ í‚¤ì›Œë“œì— ì¶”ê°€
                if prof_matches:
                    for prof_name in prof_matches:
                        if prof_name not in kws:
                            kws.append(prof_name)
                            self.logger.info(f"êµìˆ˜ëª… í‚¤ì›Œë“œ ì¶”ê°€: {prof_name}")

                if kws:
                    # í‚¤ì›Œë“œë“¤ì„ ê¸°ë³¸ ì¿¼ë¦¬ì— ì—°ê²°
                    concatenated_query = f"{query_text} {' '.join(kws)}"
                    keywords_used = kws
                    self.logger.info(f"âœ… fallback ì—°ê²°ëœ ì¿¼ë¦¬ ìƒì„±: '{concatenated_query}'")

            # ìµœì¢… ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            if concatenated_query != query_text:
                query_text = concatenated_query
                self.logger.info(f"ğŸ”— ìµœì¢… ì¿¼ë¦¬: '{query_text}' (í‚¤ì›Œë“œ {len(keywords_used)}ê°œ ì—°ê²°)")
            else:
                self.logger.info("ğŸ” ë‹¨ì¼ ì¿¼ë¦¬ ê²€ìƒ‰ ì‹¤í–‰ (ì—°ê²°í•  í‚¤ì›Œë“œ ì—†ìŒ)")

            # expanded_queriesë¥¼ Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ë‹¨ì¼ ì¿¼ë¦¬ ê²€ìƒ‰ ê°•ì œ
            expanded_queries = None

            # í•™ê³¼ íŒíŠ¸: ë¶„ì„ ë‹¨ê³„ì—ì„œ ì£¼ì…ëœ dept_hint ìš°ì„  ì‚¬ìš©
            dept_hint = query_analysis.get('dept_hint', '') if isinstance(query_analysis, dict) else ''
            self.logger.info(f"ğŸ« í•™ê³¼ íŒíŠ¸: '{dept_hint}'")

            # í•™ê³¼ ë§¤í•‘ì´ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³  ìƒìœ„ 2ê°œ í•™ê³¼ ì¶”ì¶œ
            mapping_context = kwargs.get('mapping_context', '') if isinstance(kwargs, dict) else ''
            selected_departments = []

            # previous_resultsì—ì„œ í•™ê³¼ ë§¤í•‘ ê²°ê³¼ í™•ì¸
            previous_results = kwargs.get('previous_results', {}) if isinstance(kwargs, dict) else {}
            if previous_results and 'step_1' in previous_results:
                step1_result = previous_results['step_1']
                if isinstance(step1_result, dict) and 'result' in step1_result:
                    mapping_context = step1_result['result']
                    self.logger.info(f"ğŸ” previous_resultsì—ì„œ í•™ê³¼ ë§¤í•‘ ê²°ê³¼ ë°œê²¬")

            self.logger.info(f"ğŸ—ºï¸ í•™ê³¼ ë§¤í•‘ ì»¨í…ìŠ¤íŠ¸ ì¡´ì¬: {bool(mapping_context)}")
            if mapping_context:
                self.logger.info(f"ğŸ“„ ë§¤í•‘ ì»¨í…ìŠ¤íŠ¸ ë‚´ìš©: {mapping_context[:200]}...")

            # í•™ê³¼ ë§¤í•‘ì´ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if mapping_context and 'ê°€ì¥ ìœ ì‚¬í•œ í•™ê³¼' in mapping_context:
                self.logger.info("ğŸ¯ í•™ê³¼ ë§¤í•‘ ì—ì´ì „íŠ¸ ì‹¤í–‰ë¨ - ë§¤í•‘ëœ í•™ê³¼ë§Œ ì—„ê²© í•„í„°ë§")
                try:
                    import re
                    # "ê°€ì¥ ìœ ì‚¬í•œ í•™ê³¼: XXX" íŒ¨í„´ì—ì„œ í•™ê³¼ëª… ì¶”ì¶œ
                    best_match = re.search(r"ê°€ì¥ ìœ ì‚¬í•œ í•™ê³¼:\s*([^\n]+)", mapping_context)
                    if best_match:
                        best_dept = best_match.group(1).strip()
                        selected_departments.append(best_dept)
                        self.logger.info(f"ğŸ¥‡ ë§¤í•‘ëœ í•™ê³¼: {best_dept}")

                    # ì‚¬ìš©ìê°€ íŠ¹ì • í•™ê³¼ë¥¼ ëª…ì‹œí•œ ê²½ìš°, í•´ë‹¹ í•™ê³¼ë§Œ ì—„ê²©í•˜ê²Œ í•„í„°ë§
                    # "ë‹¤ë¥¸ í›„ë³´ë“¤"ì€ í¬í•¨í•˜ì§€ ì•ŠìŒ (ì»´ê³µ = ì»´í“¨í„°ì¸ê³µì§€ëŠ¥í•™ë¶€ë§Œ)
                    self.logger.info(f"âœ… ì—„ê²© í•™ê³¼ í•„í„°ë§: {selected_departments} (ë‹¤ë¥¸ í•™ê³¼ ì œì™¸)")
                except Exception as e:
                    self.logger.error(f"âŒ í•™ê³¼ ë§¤í•‘ ì»¨í…ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨: {e}")
            else:
                self.logger.info("ğŸŒ í•™ê³¼ ë§¤í•‘ ì—ì´ì „íŠ¸ ë¯¸ì‹¤í–‰ - ì „ì²´ í•™ê³¼ì—ì„œ ê²€ìƒ‰")

            # í•™ê³¼ íŒíŠ¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if dept_hint and dept_hint not in selected_departments:
                selected_departments.append(dept_hint)
                self.logger.info(f"â• í•™ê³¼ íŒíŠ¸ ì¶”ê°€: {dept_hint}")

            self.logger.info(f"ğŸ¯ ìµœì¢… í•™ê³¼ í•„í„°: {selected_departments if selected_departments else 'ì „ì²´ í•™ê³¼'}")

            # HTTP API í˜¸ì¶œë¡œ Vector Search ì„œë¹„ìŠ¤ í˜¸ì¶œ
            self.logger.info("ğŸŒ FAISS ë²¡í„° ê²€ìƒ‰ ì„œë¹„ìŠ¤ HTTP í˜¸ì¶œ ì¤€ë¹„")
            try:
                # êµìˆ˜ëª…ì´ í¬í•¨ëœ ê²½ìš° ë” ë§ì€ ê²°ê³¼ ê²€ìƒ‰
                search_count = 50 if prof_matches else 30
                self.logger.info(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {search_count} (êµìˆ˜ëª… ê¸°ë°˜ ì¡°ì •: {bool(prof_matches)})")

                # API ìš”ì²­ í˜ì´ë¡œë“œ êµ¬ì„± (ì—°ê²°ëœ ë‹¨ì¼ ì¿¼ë¦¬ ì‚¬ìš©)
                payload = {
                    "query": query_text,
                    "count": search_count,
                    "department_filter": selected_departments if selected_departments else None,
                    "expanded_queries": None,  # ì—°ê²°ëœ ë‹¨ì¼ ì¿¼ë¦¬ë¡œ ë³€ê²½í–ˆìœ¼ë¯€ë¡œ None
                    "debug": True,
                    "keywords": keywords_used if keywords_used else None  # í‚¤ì›Œë“œ ì •ë³´ëŠ” ë””ë²„ê¹…ìš©ìœ¼ë¡œ ì „ë‹¬
                }

                self.logger.info(f"ğŸ“¦ FAISS ì„œë¹„ìŠ¤ ìš”ì²­ í˜ì´ë¡œë“œ:")
                self.logger.info(f"  ğŸ” ì—°ê²°ëœ ì¿¼ë¦¬: {payload['query']}")
                self.logger.info(f"  ğŸ“Š ê²°ê³¼ ìˆ˜: {payload['count']}")
                self.logger.info(f"  ğŸ« í•™ê³¼ í•„í„°: {payload['department_filter']}")
                self.logger.info(f"  ğŸ”„ ê²€ìƒ‰ ë°©ì‹: ë‹¨ì¼ ì¿¼ë¦¬ (ì—°ê²°ëœ í‚¤ì›Œë“œ: {len(keywords_used) if keywords_used else 0}ê°œ)")
                self.logger.info(f"  ğŸ› ë””ë²„ê·¸ ëª¨ë“œ: {payload['debug']}")
                if keywords_used:
                    self.logger.info(f"  ğŸ“‹ ì—°ê²°ëœ í‚¤ì›Œë“œ: {keywords_used}")

                # HTTP ìš”ì²­ ì „ì†¡ (SQL ì‚¬ì „ í•„í„°ë§ í¬í•¨)
                self.logger.info(f"ğŸŒ HTTP ìš”ì²­ ì „ì†¡: POST {self.faiss_service_url}")
                self.logger.info("ğŸ¯ SQL ì‚¬ì „ í•„í„°ë§ í™œì„±í™”ë¨ - FAISS ì„œë¹„ìŠ¤ì—ì„œ LLM ê¸°ë°˜ SQL ìƒì„± ìˆ˜í–‰")
                self.logger.info("ğŸ’¡ FAISS ì„œë¹„ìŠ¤ì—ì„œ ìˆ˜í–‰ë  ì‘ì—…:")
                self.logger.info("   1ï¸âƒ£ ì¿¼ë¦¬ ë¶„ì„ ë° SQL ì¡°ê±´ ì¶”ì¶œ")
                self.logger.info("   2ï¸âƒ£ LLMì„ í†µí•œ SQL WHERE ì ˆ ìƒì„±")
                self.logger.info("   3ï¸âƒ£ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ê³¼ëª© ì‚¬ì „ í•„í„°ë§")
                self.logger.info("   4ï¸âƒ£ í•„í„°ë§ëœ ê³¼ëª©ë“¤ì— ëŒ€í•´ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°")
                response = await self.http_client.post(self.faiss_service_url, json=payload)
                self.logger.info(f"ğŸ“¡ HTTP ì‘ë‹µ ìˆ˜ì‹ : {response.status_code}")

                if response.status_code == 200:
                    response_data = response.json()
                    self.logger.info(f"ğŸ” ì‘ë‹µ íƒ€ì…: {type(response_data)}, ë‚´ìš©: {str(response_data)[:200]}")

                    # ì‘ë‹µì´ dict í˜•íƒœë©´ results í‚¤ì—ì„œ ì¶”ì¶œ
                    if isinstance(response_data, dict):
                        results = response_data.get('results', [])
                        self.logger.info(f"ğŸ“¦ ë”•ì…”ë„ˆë¦¬ ì‘ë‹µì—ì„œ ê²°ê³¼ ì¶”ì¶œ: {len(results)}ê°œ í•­ëª©")

                        # SQL ì •ë³´ê°€ ìˆìœ¼ë©´ ë¡œê¹…
                        if 'sql_info' in response_data:
                            sql_info = response_data['sql_info']
                            self.logger.info("ğŸ› ï¸ SQL ì¿¼ë¦¬ ìƒì„± ì •ë³´:")
                            if sql_info.get('generated_sql'):
                                self.logger.info(f"   ğŸ“ ìƒì„±ëœ SQL: {sql_info.get('generated_sql')}")
                                self.logger.info("âœ… SQL ì¿¼ë¦¬ ì‹¤í–‰ë¨ - FAISS ì„œë¹„ìŠ¤ì—ì„œ LLM ê¸°ë°˜ SQL ìƒì„± ë° ì‹¤í–‰ ì™„ë£Œ")
                            if sql_info.get('filtered_count') is not None:
                                self.logger.info(f"   ğŸ¯ SQL í•„í„°ë§ ê²°ê³¼: {sql_info.get('filtered_count')}ê°œ ê³¼ëª©")
                            if sql_info.get('total_courses'):
                                self.logger.info(f"   ğŸ“Š ì „ì²´ ê³¼ëª© ìˆ˜: {sql_info.get('total_courses')}ê°œ")
                        else:
                            # SQL ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°ì—ë„ SQLì´ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ ê²°ê³¼ë¥¼ í†µí•´ ë¶„ì„
                            if results and len(results) > 0:
                                # ê²°ê³¼ê°€ ìˆìœ¼ë©´ SQL ì‚¬ì „ í•„í„°ë§ì´ ì‘ë™í–ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                                self.logger.info("ğŸ’¡ SQL ì‹¤í–‰ ì—¬ë¶€ ë¶„ì„: ê²€ìƒ‰ ê²°ê³¼ ì¡´ì¬ â†’ SQL ì‚¬ì „ í•„í„°ë§ ì •ìƒ ì‘ë™")
                            else:
                                self.logger.warning("âš ï¸ SQL ì‹¤í–‰ ì—¬ë¶€ ë¶„ì„: ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ â†’ SQL í•„í„°ë§ í™•ì¸ í•„ìš”")
                    elif isinstance(response_data, list):
                        results = response_data
                        self.logger.info(f"ğŸ“‹ ë¦¬ìŠ¤íŠ¸ ì‘ë‹µ ì§ì ‘ ì‚¬ìš©: {len(results)}ê°œ í•­ëª©")
                    elif isinstance(response_data, str):
                        self.logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ìì—´ ì‘ë‹µ: {response_data}")
                        results = []
                    else:
                        self.logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ í˜•íƒœ: {type(response_data)}")
                        results = []

                    self.logger.info(f"âœ… ë²¡í„° ê²€ìƒ‰ ì„±ê³µ: {len(results)}ê°œ ê²°ê³¼")

                    # ê²°ê³¼ ìƒì„¸ ë¶„ì„
                    if results and isinstance(results, list):
                        similarities = [r.get('similarity_score', 0.0) if isinstance(r, dict) else 0.0 for r in results]
                        max_sim = max(similarities) if similarities else 0.0
                        min_sim = min(similarities) if similarities else 0.0
                        avg_sim = sum(similarities) / len(similarities) if similarities else 0.0

                        self.logger.info(f"ğŸ“ˆ ìœ ì‚¬ë„ í†µê³„: ìµœëŒ€={max_sim:.3f}, ìµœì†Œ={min_sim:.3f}, í‰ê· ={avg_sim:.3f}")

                        # ìƒìœ„ 3ê°œ ê²°ê³¼ ìƒì„¸ ë¡œê¹…
                        self.logger.info("ğŸ” ìƒìœ„ 3ê°œ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸:")
                        for i, r in enumerate(results[:3]):
                            if isinstance(r, dict):
                                name = r.get('name', 'ì•Œìˆ˜ì—†ìŒ')
                                dept = r.get('department_full_name', r.get('department', 'ì•Œìˆ˜ì—†ìŒ'))
                                score = r.get('similarity_score', 0.0)
                                prof = r.get('professor', 'ì •ë³´ì—†ìŒ')
                                self.logger.info(f"   {i+1}. {name} (í•™ê³¼: {dept}, êµìˆ˜: {prof}, ì ìˆ˜: {score:.3f})")

                        departments = [r.get('department_full_name', 'ì•Œìˆ˜ì—†ìŒ') if isinstance(r, dict) else 'ì•Œìˆ˜ì—†ìŒ' for r in results[:5]]
                        dept_counts = {}
                        for dept in departments:
                            dept_counts[dept] = dept_counts.get(dept, 0) + 1
                        self.logger.info(f"ğŸ« ìƒìœ„ 5ê°œ ê²°ê³¼ í•™ê³¼ ë¶„í¬: {dept_counts}")
                else:
                    self.logger.error(f"âŒ Vector Search API ì˜¤ë¥˜: status={response.status_code}")
                    try:
                        error_detail = response.text
                        self.logger.error(f"âŒ ì˜¤ë¥˜ ìƒì„¸: {error_detail[:200]}...")
                    except:
                        pass
                    return f"ë²¡í„° ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {response.status_code}"

            except Exception as e:
                self.logger.error(f"âŒ Vector Search HTTP í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                import traceback
                self.logger.error(f"âŒ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
                return f"ë²¡í„° ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

            if results and len(results) > 0:
                self.logger.info(f"ğŸ“‹ ê²°ê³¼ í¬ë§·íŒ… ì‹œì‘: {len(results)}ê°œ ê²°ê³¼ â†’ ì „ì²´ í‘œì‹œ")
                formatted_content = f"'{user_message}'ì™€ ê´€ë ¨ëœ ê³¼ëª©ë“¤ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"

                # ëª¨ë“  ê²°ê³¼ í¬ë§·íŒ…
                for i, item in enumerate(results):
                    name = item.get('name', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    dept = item.get('department_full_name', item.get('department', 'ì•Œ ìˆ˜ ì—†ìŒ'))
                    desc = item.get('gpt_description', 'ì„¤ëª… ì—†ìŒ')
                    similarity = item.get('similarity_score', 0.0)

                    # SQL ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                    professor = item.get('professor', 'ì •ë³´ì—†ìŒ')
                    credits = item.get('credits', 0)
                    course_code = item.get('course_code', '')
                    prerequisite = item.get('prerequisite', 'ì—†ìŒ')
                    target_grade = item.get('target_grade', '')
                    schedule = item.get('schedule', 'ì •ë³´ì—†ìŒ')
                    location = item.get('location', 'ì •ë³´ì—†ìŒ')
                    delivery_mode = item.get('delivery_mode', 'ì •ë³´ì—†ìŒ')

                    formatted_content += f"{i+1}. **{name}**\n"
                    formatted_content += f"   - í•™ê³¼: {dept}\n"
                    formatted_content += f"   - êµìˆ˜: {professor}\n"
                    if location != 'ì •ë³´ì—†ìŒ':
                        formatted_content += f"   - ê°•ì˜ì‹¤: {location}\n"
                    if schedule != 'ì •ë³´ì—†ìŒ':
                        formatted_content += f"   - ì‹œê°„í‘œ: {schedule}\n"
                    formatted_content += f"   - í•™ì : {credits}í•™ì \n"
                    if course_code:
                        formatted_content += f"   - ê³¼ëª©ì½”ë“œ: {course_code}\n"
                    formatted_content += f"   - ì„ ìˆ˜ê³¼ëª©: {prerequisite}\n"
                    if target_grade:
                        formatted_content += f"   - ëŒ€ìƒí•™ë…„: {target_grade}\n"
                    if delivery_mode != 'ì •ë³´ì—†ìŒ':
                        formatted_content += f"   - ìˆ˜ì—…ë°©ì‹: {delivery_mode}\n"
                    formatted_content += f"   - ìœ ì‚¬ë„: {similarity:.3f}\n"
                    formatted_content += f"   - ì„¤ëª…: {desc[:200]}...\n\n"

                # í•™ê³¼ í•„í„° ì •ë³´ ì¶”ê°€
                if selected_departments and mapping_context and 'ê°€ì¥ ìœ ì‚¬í•œ í•™ê³¼' in mapping_context:
                    dept_list = ", ".join(selected_departments)
                    formatted_content += f"(ì°¸ê³ : í•™ê³¼ ë§¤í•‘ ê²°ê³¼ '{dept_list}' í•™ê³¼ì—ì„œ ê²€ìƒ‰í•œ ê²°ê³¼ì…ë‹ˆë‹¤)\n\n"
                    self.logger.info(f"ğŸ¯ í•™ê³¼ ë§¤í•‘ ê¸°ë°˜ í•„í„°ë§ ì ìš©: {dept_list}")
                elif dept_hint:
                    formatted_content += f"(ì°¸ê³ : '{dept_hint}' ê´€ë ¨ ê²°ê³¼ë¥¼ ìš°ì„  í‘œê¸°í–ˆìŠµë‹ˆë‹¤)\n\n"
                    self.logger.info(f"ğŸ’¡ í•™ê³¼ íŒíŠ¸ ê¸°ë°˜ í•„í„°ë§: {dept_hint}")


                self.logger.info(f"âœ… FAISS ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼ ë°˜í™˜")
                self.logger.info("="*60)
                return formatted_content
            else:
                self.logger.warning(f"âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: '{user_message}'")
                self.logger.info("="*60)
                return f"'{user_message}'ì™€ ê´€ë ¨ëœ ê³¼ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        except Exception as e:
            self.logger.error(f"âŒ Vector Search ì „ì²´ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            self.logger.error(f"âŒ ì „ì²´ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
            self.logger.info("="*60)
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def get_fallback_message(self) -> str:
        return "ë²¡í„° ê²€ìƒ‰ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    async def search(self, user_message: str, query_analysis: Dict, **kwargs) -> str:
        """
        Legacy compatibility method that calls handle()

        This method exists for backward compatibility with code that might
        still be calling the old .search() method instead of .handle()
        """
        return await self.handle(user_message, query_analysis, **kwargs)

    # ë” ì´ìƒì˜ í•™ê³¼ ì¶”ì¶œì€ ìƒìœ„ ë¼ìš°í„°/í”„ë¡œì„¸ì„œì—ì„œ ìˆ˜í–‰
