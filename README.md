
# ğŸ¤– JBNU AI Mentor - ë¡œì»¬ ì‹¤í–‰ ê°€ì´ë“œ

## Frontend (port: 5173)

### ì„¤ì¹˜
```bash
cd open-webui
npm install
```

### ì‹¤í–‰

```bash
cd open-webui
npm run dev
```

---

## Backend (port: 8080)

### ì„¤ì¹˜

```bash
conda create --name open-webui python=3.11
conda activate open-webui
cd open-webui/backend/
pip install -r requirements.txt -U
sh dev.sh
```

### ì‹¤í–‰

```bash
conda activate open-webui
cd open-webui/backend/
sh dev.sh
```

---

## Pipeline (port: 9099)

### ì„¤ì¹˜

```bash
conda activate open-webui
cd pipelines/
pip install -r requirements.txt
sudo apt update
sudo apt install dos2unix
sed -i 's/\r$//' start.sh
./start.sh
```

### ì‹¤í–‰

```bash
conda activate open-webui
cd pipelines/
./start.sh
```

---

## Open WebUI â†” Pipelines ì—°ë™

1. **Admin Panel** > **Settings** > **Connections**
2. **OpenAI API ì—°ê²° ê´€ë¦¬** í´ë¦­

   * URL: `http://localhost:9099`
   * Key: `0p3n-w3bu!`

---

## Pipeline ì¶”ê°€

1. **Admin Panel** > **Settings** > **Pipeline**
2. **ì—…ë¡œë“œ íŒŒì´í”„ë¼ì¸** â†’ íŒŒì¼ ì„ íƒ â†’ ì˜†ì˜ ë²„íŠ¼ í´ë¦­ â†’ **ì €ì¥**

---

## llm-agent-main Uvicorn (port: 8001)

```bash
conda activate open-webui
cd ai_modules/llm_agent-main/
uvicorn main:app --host 0.0.0.0 --port 8001
```

> **Tip:** `open-webui backend, pipeline`ê³¼ ë™ì¼í•œ `localhost` ì„¤ì •ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

---

## PDF ì‘ë‹µ ì²˜ë¦¬

ì±„íŒ… ë©”ì‹œì§€ `content` ì— Markdown ë§í¬ë¡œ PDF ë‹¤ìš´ë¡œë“œ ë§í¬ë¥¼ ì œê³µí•˜ì„¸ìš”:

```python
"content" : f"[PDF ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ ë§í¬]({pdf_url})"
```


---
## Stream=Falseì¼ ë•Œ

```jsonc
// stream=False ì‘ë‹µ ì˜ˆì‹œ
{
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "ì•ˆë…•í•˜ì„¸ìš”! ìš”ì²­í•˜ì‹  ë‚´ìš©ì„ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.\n\n[PDF ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ](https://example.com/report.pdf)",
        "attachments": [
          {
            "type": "image",
            "url": "https://example.com/image.png",
            "name": "image.png"
          },
          {
            "type": "file",
            "url": "https://example.com/report.pdf",
            "name": "report.pdf"
          }
        ]
      },
      "finish_reason": "stop"
    }
  ]
}
```

## Stream=Trueì¼ ë•Œ ì‘ë‹µ ì²˜ë¦¬ (Server-Sent Events í˜•ì‹)

* **í—¤ë”**

  ```
  HTTP/1.1 200 OK
  Content-Type: text/event-stream
  Connection: keep-alive
  ```

* **í† í° ë¸íƒ€ ì´ë²¤íŠ¸ ì˜ˆì‹œ**

  ```http
  data: {"id":"chatcmpl-xxx","object":"chat.completion.chunk",
         "choices":[{"delta":{"content":"ë§›"},
                     "index":0,
                     "finish_reason":null}]}

  data: {"id":"chatcmpl-xxx","object":"chat.completion.chunk",
         "choices":[{"delta":{"content":"ìˆ"},
                     "index":0,
                     "finish_reason":null}]}

  data: {"id":"chatcmpl-xxx","object":"chat.completion.chunk",
         "choices":[{"delta":{"content":"ë‹¤"},
                     "index":0,
                     "finish_reason":null}]}

  data: [DONE]
  ```

* **FastAPI ì œë„ˆë ˆì´í„° ì˜ˆì‹œ**

  ```python
  async def event_generator():
      for token in ["ë§›", "ìˆ", "ë‹¤"]:
          chunk = {
              "id": "chatcmpl-xxx",
              "object": "chat.completion.chunk",
              "choices": [{
                  "delta": {"content": token},
                  "index": 0,
                  "finish_reason": None
              }]
          }
          yield f"data: {json.dumps(chunk)}\n\n"
          await asyncio.sleep(0.1)

      # ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
      yield "data: [DONE]\n\n"
  ```

  ```python
  return StreamingResponse(
      event_generator(),
      media_type="text/event-stream"
  )
  ```





---

## ğŸ“„ ê¸°ëŠ¥ í•­ëª© (ì§„í–‰ ì¤‘)

* [x] PDF ì²˜ë¦¬
* [x] ëŒ€í™” stream ì²˜ë¦¬
* [ ] ëŒ€í™” ê¸°ë¡ ê´€ë¦¬

---

## ğŸ§¼ ì°¸ê³ ì‚¬í•­

* ëª¨ë“  ì„œë²„ëŠ” `.env` í™˜ê²½íŒŒì¼ì„ í†µí•´ ë¯¼ê°ì •ë³´(API KEY ë“±)ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
